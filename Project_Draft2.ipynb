{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries, Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from numpy import linalg as LA\n",
    "from sklearn.cluster import KMeans\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from itertools import combinations\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths:\n",
    "price_path = '/Users/tuckeringlefield/Desktop/FinanceData/price_data_from_shardar.csv'\n",
    "cap_path = '/Users/tuckeringlefield/Desktop/FinanceData/cap_data_from_shardar.csv'\n",
    "#price_path = \"C:/Users/lukee/Downloads/price_data_from_shardar.csv\"\n",
    "#cap_path = \"C:/Users/lukee/Downloads/cap_data_from_shardar.csv\"\n",
    "\n",
    "# Reading Data:\n",
    "prices_df = pd.read_csv(price_path, index_col='date')\n",
    "caps_df = pd.read_csv(cap_path, index_col='date')\n",
    "\n",
    "# Drop troubled stock...\n",
    "prices_df.drop([\"MGI\", \"MDLZ\", \"DWA\", \"ICE\"], axis=1, inplace=True)\n",
    "caps_df.drop([\"MGI\", \"MDLZ\", \"DWA\", \"ICE\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Convert dates to datetime\n",
    "prices_df.index = pd.to_datetime(prices_df.index)\n",
    "\n",
    "# Get the initial start and end date\n",
    "start_date = prices_df.index[0]\n",
    "end_date = prices_df.index[-1]\n",
    "\n",
    "# Download additional data:\n",
    "spy_data = yf.download('SPY', start=start_date, end=end_date, interval='1d')\n",
    "spy_data = pd.DataFrame(spy_data[\"Adj Close\"])\n",
    "spy_data.rename({\"Adj Close\": 'SPY'}, inplace=True, axis=1)\n",
    "\n",
    "# Set up dataframes:\n",
    "prices_with_market = prices_df.merge(spy_data, how='left', left_index=True, right_index=True)\n",
    "df_diff = prices_with_market.diff().dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the top ten largest market cap stocks\n",
    "def find_top_stocks(dataframe, date_start, date_end, num_stocks):\n",
    "    target_date = date_end + 1\n",
    "    selected_row = caps_df.iloc[target_date]\n",
    "    selected_row_no_null = selected_row.dropna()\n",
    "    stocks_list = selected_row_no_null.nlargest(num_stocks).index.tolist()\n",
    "    return stocks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter the DF\n",
    "def filter_diff_df(dataframe, date_start, date_end, stocks_list):\n",
    "    desired_columns = stocks_list.copy()\n",
    "    desired_columns.append(\"SPY\")\n",
    "    #print(desired_columns)\n",
    "    filtered_df = dataframe[desired_columns]\n",
    "    filtered_df = filtered_df[date_start:date_end].diff()#.dropna()\n",
    "    # print(\"Filtered diff df len (before dropna):\", len(filtered_df))\n",
    "    # print(filtered_df.head())\n",
    "    # print(len(filtered_df))\n",
    "    # print(filtered_df.isnull().sum())\n",
    "    filtered_df = filtered_df.dropna()\n",
    "    # print(\"Filtered diff df len (after dropna):\", len(filtered_df))\n",
    "    # print(len(filtered_df))\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df_by_dates(dataframe, date_start, date_end, stocks_list):\n",
    "    desired_columns = stocks_list.copy()\n",
    "    desired_columns.append(\"SPY\")\n",
    "    filtered_df = dataframe[desired_columns]\n",
    "    filtered_df = filtered_df[date_start:date_end]\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the residuals\n",
    "def calculate_residuals(df, stocks_list):\n",
    "    res_df = pd.DataFrame()\n",
    "    for stk in stocks_list:\n",
    "        res_df[stk] = df[stk]-df[stk+\"_beta\"]*df[\"SPY\"]\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to cluster the matrix\n",
    "def cluster_the_matrix(df, num_clusters):\n",
    "    A = abs(df.corr().values)\n",
    "    #print(f'A Shape: {A.shape}')\n",
    "    D = np.diag(A.sum(axis=1))\n",
    "    #print(f'D Shape: {D.shape}')\n",
    "    L = D - A\n",
    "    #print(f'L Shape: {L.shape}')\n",
    "    eigenvalues, eigenvectors = LA.eig(L)\n",
    "    X = eigenvectors[:,:num_clusters]\n",
    "    #print(f'X Shape: {X.shape}')\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=2, n_init=20).fit(X)\n",
    "    #print(\"Kmeans Labels:\")\n",
    "    #print(kmeans.labels_)\n",
    "    #print(df.columns)\n",
    "\n",
    "    cluster_dict = {}\n",
    "\n",
    "    # Iterate over the indices of cluster_list\n",
    "    for i in range(len(kmeans.labels_)):\n",
    "        cluster_number = kmeans.labels_[i]\n",
    "        stock_name = df.columns[i]\n",
    "\n",
    "        # Check if cluster_number is already a key in the dictionary\n",
    "        if cluster_number in cluster_dict:\n",
    "            cluster_dict[cluster_number].append(stock_name)\n",
    "        else:\n",
    "            cluster_dict[cluster_number] = [stock_name]\n",
    "\n",
    "    # Cluster diagram:\n",
    "    # fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "    # scatter = ax.scatter(X[:, 0], X[:, 1], c=kmeans.labels_)\n",
    "    # unique_labels = {label: idx for idx, label in enumerate(set(kmeans.labels_))}\n",
    "    # handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=scatter.cmap(scatter.norm(value)), markersize=10)\n",
    "    #        for value in unique_labels.values()]\n",
    "    # labels = unique_labels.keys()\n",
    "    # ax.legend(handles, labels, title=\"Clusters\", loc=\"best\", bbox_to_anchor=(1, 1))\n",
    "    # ax.set_title(f'K-Means Clustering Results with K={num_clusters}')\n",
    "    # plt.show()\n",
    "\n",
    "    return cluster_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the cointegrated pairs\n",
    "def find_cointegrated_pairs(dataframe, cluster_dict, sig_level):\n",
    "    cointegrated_pairs = []\n",
    "    for cluster_num, stocks in cluster_dict.items():\n",
    "      for stock1, stock2 in combinations(stocks, 2):\n",
    "          pvalue1 = coint(dataframe[stock1], dataframe[stock2])[1]\n",
    "          pvalue2 = coint(dataframe[stock2], dataframe[stock1])[1]\n",
    "          if pvalue1 < sig_level and pvalue2 < sig_level:\n",
    "              cointegrated_pairs.append((stock1, stock2))\n",
    "    return cointegrated_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check on existing pairs\n",
    "def is_still_conintegrated(dataframe, pair, sig_level):\n",
    "    stock1 = pair[0]\n",
    "    stock2 = pair[1]\n",
    "    pvalue1 = coint(dataframe[stock1], dataframe[stock2])[1]\n",
    "    pvalue2 = coint(dataframe[stock2], dataframe[stock1])[1]\n",
    "    if pvalue1 < sig_level and pvalue2 < sig_level:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekly function to calculate the beta of the pair\n",
    "def calculate_beta_for_pair(dataframe, pair):\n",
    "    asst1 = pair[0]\n",
    "    asst2 = pair[1]\n",
    "\n",
    "    train = dataframe[[asst1, asst2]]\n",
    "\n",
    "    beta = train.cov().iloc[0, 1]/train[asst2].var()\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the spread data\n",
    "def get_spread_limits_for_past_months(dataframe, pair, beta):\n",
    "    asst1 = pair[0]\n",
    "    asst2 = pair[1]\n",
    "    asst1_mean = dataframe[asst1].mean() \n",
    "    asst2_mean = dataframe[asst2].mean() \n",
    "    spread_data = None\n",
    "    order = []\n",
    "    if asst1_mean > asst2_mean:\n",
    "        spread_data = dataframe[asst1]-beta*dataframe[asst2]\n",
    "        order = [asst1, asst2]\n",
    "    else:\n",
    "        spread_data = dataframe[asst2]-beta*dataframe[asst1]\n",
    "        order = [asst2, asst1]\n",
    "    mean = spread_data.mean()\n",
    "    std_dev = spread_data.std()\n",
    "    lower_limit = mean - (2*std_dev)\n",
    "    upper_limit = mean + (2*std_dev)\n",
    "    \n",
    "    return upper_limit, lower_limit, order, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_spread_charts(data_series, upper_bound, lower_bound, mean_value, pair_name):\n",
    "    # Extract dates and values\n",
    "    dates = data_series.index\n",
    "    values = data_series.values\n",
    "    \n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot the average line\n",
    "    plt.axhline(y=mean_value, color='blue', linestyle='-', linewidth=1, label='Mean for Past 3 months')\n",
    "    \n",
    "    # Plot the dashed lines for ±2 standard deviations\n",
    "    plt.axhline(y=upper_bound, color='red', linestyle='--', linewidth=1, label='+2 Std Dev')\n",
    "    plt.axhline(y=lower_bound, color='red', linestyle='--', linewidth=1, label='-2 Std Dev')\n",
    "    \n",
    "    # Plot the individual data points\n",
    "    plt.scatter(dates, values, color='black', zorder=5)\n",
    "    \n",
    "    # Annotate the plot\n",
    "    plt.title(f'Spread data for: {pair_name} for monitoring week')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_pair_for_week(pair, pair_dict, start_date_index, end_date_index, curr_week_start_index, currently_trading_stocks):\n",
    "    # Access the data\n",
    "    global prices_with_market\n",
    "    # Get dates as strings\n",
    "    start_date_string = prices_with_market.index[start_date_index].strftime('%Y-%m-%d')\n",
    "    end_date_string = prices_with_market.index[end_date_index].strftime('%Y-%m-%d')\n",
    "    curr_week_date_string = prices_with_market.index[curr_week_start_index].strftime('%Y-%m-%d')\n",
    "    # Get data\n",
    "    forward_three_months_data = prices_with_market[start_date_index+7 : end_date_index]\n",
    "    past_three_month_data = prices_with_market[start_date_index : curr_week_start_index]\n",
    "    # Check for nulls \n",
    "    nulls_in_three_months_for_stock1 = forward_three_months_data[pair[0]].isnull().sum()\n",
    "    nulls_in_three_months_for_stock2 = forward_three_months_data[pair[1]].isnull().sum()\n",
    "    if nulls_in_three_months_for_stock1 > 0 or nulls_in_three_months_for_stock2 > 0:\n",
    "        pair_dict['End_dates'].append(end_date_string)\n",
    "        pair_dict['Still_consecutive'] = False\n",
    "        pair_dict['Should_monitor'] = False\n",
    "        pair_dict['Status_message'] = \"Null Values: Can't Trade\"\n",
    "        return pair_dict\n",
    "    else:\n",
    "        # Check if they are still cointegrated\n",
    "        coint_at_start_week = is_still_conintegrated(past_three_month_data, pair, 0.05)\n",
    "        if coint_at_start_week:\n",
    "            pass\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_group_of_pairs(coint_dict, stop_after_weeks):\n",
    "    # Access the data\n",
    "    global prices_with_market\n",
    "    # List of currently trading stocks\n",
    "    currently_trading_stocks = []\n",
    "    # variable to track the weeks running\n",
    "    weeks_running = 0\n",
    "    while (weeks_running < stop_after_weeks):\n",
    "        print(f\"---------------------------- WEEKS RUNNING {weeks_running + 1} -------------------------------------\")\n",
    "        # Calculate index\n",
    "        start_date_index = ((weeks_running+1)*7)\n",
    "        end_date_index = ((weeks_running+1)*7) + 97\n",
    "        curr_week_start_index = ((weeks_running+1)*7) + 89\n",
    "        # Get data \n",
    "        three_month_plus_one_week_df = prices_with_market[start_date_index : end_date_index]\n",
    "\n",
    "        # Iterate over every pair in pair_dict\n",
    "        for key in coint_dict:\n",
    "            if coint_dict[key]['Still_consecutive']:\n",
    "                updated_vals = monitor_pair_for_week(key, coint_dict[key], start_date_index, end_date_index, curr_week_start_index, currently_trading_stocks)\n",
    "                coint_dict[key] = updated_vals\n",
    "        # Increment weeks_running\n",
    "        weeks_running +=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME!!\n",
    "def print_overall_display(pairs_dictionary):\n",
    "    data = pairs_dictionary\n",
    "\n",
    "    # Function to convert date strings to datetime objects\n",
    "    def str_to_date(date_str):\n",
    "        return datetime.strptime(date_str, '%Y-%m-%d')\n",
    "\n",
    "    # Determine the number of plots needed\n",
    "    num_keys = len(data)\n",
    "    num_plots = (num_keys + 4) // 5  # Calculate the number of plots needed, rounding up\n",
    "\n",
    "    # Iterate over the required number of plots\n",
    "    for plot_index in range(num_plots):\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "        start_index = plot_index * 5\n",
    "        end_index = min(start_index + 5, num_keys)\n",
    "\n",
    "        # Iterate over the data to plot\n",
    "        for idx, (key, value) in enumerate(list(data.items())[start_index:end_index]):\n",
    "            actual_idx = start_index + idx\n",
    "            label = f\"{key[0]}-{key[1]}\"\n",
    "        \n",
    "            # Extract periods and events\n",
    "            periods_start = [str_to_date(date) for date in value[2]]\n",
    "            periods_end = [str_to_date(date) for date in value[3]]\n",
    "            event_lists = value[3]\n",
    "        \n",
    "            # Plot each period as a line\n",
    "            for start, end in zip(periods_start, periods_end):\n",
    "                ax.plot([start, end], [idx, idx], color='black')\n",
    "        \n",
    "            # Plot each event as a dot\n",
    "            for events in event_lists:\n",
    "                event_dates = [str_to_date(date) for date in events]\n",
    "                ax.plot(event_dates, [idx] * len(event_dates), 'o', color='red')\n",
    "\n",
    "            # Add the label for the pair on the Y-axis\n",
    "            #ax.text(periods_start[0], idx, label, verticalalignment='center', fontsize=12, horizontalalignment='right')\n",
    "\n",
    "        # Formatting the plot\n",
    "        ax.set_yticks(range(5))\n",
    "        ax.set_yticklabels([f\"{key[1]}-{key[2]}\" for key, _ in list(data.items())[start_index:end_index]], fontsize=12, horizontalalignment='right')\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "        plt.xticks(rotation=45) \n",
    "        plt.xlabel('Date')\n",
    "        plt.title(f'Event Timelines (Plot {plot_index + 1})')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "coint_dict = {\n",
    "    (\"INTC\", \"ORCL\") : {\n",
    "        \"Still_consecutive\" : True,\n",
    "        \"Should_monitor\" : True,\n",
    "        \"Can_Trade\" : True,\n",
    "        \"Status_message\" : \"Open to trade\",\n",
    "        \"Start_dates\" : [],\n",
    "        \"End_dates\" : [],\n",
    "        \"Open_trade_days\" : [],\n",
    "        \"Close_trade_days\" : []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- WEEKS RUNNING 1 -------------------------------------\n",
      "{'Still_consecutive': True, 'Should_monitor': True, 'Can_Trade': True, 'Status_message': 'Open to trade', 'Start_dates': [], 'End_dates': [], 'Open_trade_days': [], 'Close_trade_days': []}\n",
      "---------------------------- WEEKS RUNNING 2 -------------------------------------\n",
      "{'Still_consecutive': True, 'Should_monitor': True, 'Can_Trade': True, 'Status_message': 'Open to trade', 'Start_dates': [], 'End_dates': [], 'Open_trade_days': [], 'Close_trade_days': []}\n",
      "---------------------------- WEEKS RUNNING 3 -------------------------------------\n",
      "{'Still_consecutive': True, 'Should_monitor': True, 'Can_Trade': True, 'Status_message': 'Open to trade', 'Start_dates': [], 'End_dates': [], 'Open_trade_days': [], 'Close_trade_days': []}\n",
      "---------------------------- WEEKS RUNNING 4 -------------------------------------\n",
      "{'Still_consecutive': True, 'Should_monitor': True, 'Can_Trade': True, 'Status_message': 'Open to trade', 'Start_dates': [], 'End_dates': [], 'Open_trade_days': [], 'Close_trade_days': []}\n",
      "---------------------------- WEEKS RUNNING 5 -------------------------------------\n",
      "{'Still_consecutive': True, 'Should_monitor': True, 'Can_Trade': True, 'Status_message': 'Open to trade', 'Start_dates': [], 'End_dates': [], 'Open_trade_days': [], 'Close_trade_days': []}\n"
     ]
    }
   ],
   "source": [
    "results = monitor_group_of_pairs(coint_dict, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
