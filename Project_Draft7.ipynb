{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports, Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from numpy import linalg as LA\n",
    "from sklearn.cluster import KMeans\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from itertools import combinations\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATW</th>\n",
       "      <th>A</th>\n",
       "      <th>AA</th>\n",
       "      <th>AAAB</th>\n",
       "      <th>AABC</th>\n",
       "      <th>AAC1</th>\n",
       "      <th>AACC</th>\n",
       "      <th>AACE</th>\n",
       "      <th>AACH</th>\n",
       "      <th>AADI</th>\n",
       "      <th>...</th>\n",
       "      <th>ZVIA</th>\n",
       "      <th>ZVOI</th>\n",
       "      <th>ZVRA</th>\n",
       "      <th>ZVUE</th>\n",
       "      <th>ZVXI</th>\n",
       "      <th>ZY</th>\n",
       "      <th>ZYME</th>\n",
       "      <th>ZYNE</th>\n",
       "      <th>ZYXI</th>\n",
       "      <th>ZZ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>0.265785</td>\n",
       "      <td>14.803789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.074688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>0.355094</td>\n",
       "      <td>13.938379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>0.597657</td>\n",
       "      <td>15.593232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082724</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>0.377474</td>\n",
       "      <td>6.688876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>0.698268</td>\n",
       "      <td>8.061751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.061952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10806 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ATW          A  AA      AAAB      AABC      AAC1  AACC  \\\n",
       "date                                                                      \n",
       "2000-01-03  0.265785  14.803789 NaN  0.002968  0.000000  0.055383   NaN   \n",
       "2000-01-04  0.355094  13.938379 NaN  0.001050  0.000000  0.093997   NaN   \n",
       "2000-01-05  0.597657  15.593232 NaN  0.002262  0.000000  0.082724   NaN   \n",
       "2000-01-06  0.377474   6.688876 NaN  0.003307  0.000000  0.071145   NaN   \n",
       "2000-01-07  0.698268   8.061751 NaN  0.001843  0.000426  0.061952   NaN   \n",
       "\n",
       "                AACE  AACH  AADI  ...  ZVIA  ZVOI  ZVRA  ZVUE      ZVXI  ZY  \\\n",
       "date                              ...                                         \n",
       "2000-01-03  0.074688   NaN   NaN  ...   NaN   NaN   NaN   NaN  0.010821 NaN   \n",
       "2000-01-04  0.036322   NaN   NaN  ...   NaN   NaN   NaN   NaN  0.001050 NaN   \n",
       "2000-01-05  0.042248   NaN   NaN  ...   NaN   NaN   NaN   NaN  0.002725 NaN   \n",
       "2000-01-06  0.022496   NaN   NaN  ...   NaN   NaN   NaN   NaN  0.006309 NaN   \n",
       "2000-01-07  0.005193   NaN   NaN  ...   NaN   NaN   NaN   NaN  0.033459 NaN   \n",
       "\n",
       "            ZYME  ZYNE  ZYXI  ZZ  \n",
       "date                              \n",
       "2000-01-03   NaN   NaN   NaN NaN  \n",
       "2000-01-04   NaN   NaN   NaN NaN  \n",
       "2000-01-05   NaN   NaN   NaN NaN  \n",
       "2000-01-06   NaN   NaN   NaN NaN  \n",
       "2000-01-07   NaN   NaN   NaN NaN  \n",
       "\n",
       "[5 rows x 10806 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap_path = '/Users/tuckeringlefield/Desktop/Data_Science/Math_4920/Stocks_Data/cap_data_from_shardar.csv'\n",
    "price_path = \"/Users/tuckeringlefield/Desktop/Data_Science/Math_4920/Stocks_Data/price_data_from_shardar.csv\"\n",
    "\n",
    "# Reading Data:\n",
    "prices_df = pd.read_csv(price_path, index_col='date')\n",
    "caps_df = pd.read_csv(cap_path, index_col='date')\n",
    "\n",
    "# Drop troubled stock...\n",
    "prices_df.drop([\"MGI\", \"MDLZ\", \"DWA\", \"ICE\"], axis=1, inplace=True)\n",
    "caps_df.drop([\"MGI\", \"MDLZ\", \"DWA\", \"ICE\"], axis=1, inplace=True)\n",
    "\n",
    "prices_df.head()\n",
    "caps_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "prices_df.index = pd.to_datetime(prices_df.index)\n",
    "\n",
    "# Get the initial start and end date\n",
    "start_date = prices_df.index[0]\n",
    "end_date = prices_df.index[-1]\n",
    "\n",
    "# Download additional data:\n",
    "spy_data = yf.download('SPY', start=start_date, end=end_date, interval='1d')\n",
    "spy_data = pd.DataFrame(spy_data[\"Adj Close\"])\n",
    "spy_data.rename({\"Adj Close\": 'SPY'}, inplace=True, axis=1)\n",
    "\n",
    "# Set up dataframes:\n",
    "prices_with_market = prices_df.merge(spy_data, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Length: 5787\n",
      "Train Length: 2894\n"
     ]
    }
   ],
   "source": [
    "# Pulling rougly the first half of data\n",
    "num_rows = len(prices_df)\n",
    "print(f'Original Length: {num_rows}')\n",
    "train_df = prices_df[:np.round(num_rows/2).astype(int)]\n",
    "num_rows = len(train_df)\n",
    "print(f'Train Length: {num_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10806\n",
      "2467\n"
     ]
    }
   ],
   "source": [
    "# Let's identify stocks with no null values\n",
    "complete_stock_list = train_df.columns\n",
    "non_null_stocks = []\n",
    "for stock in complete_stock_list:\n",
    "    # get the count of nulls\n",
    "    null_count = train_df[stock].isnull().sum()\n",
    "    if null_count == 0:\n",
    "        non_null_stocks.append(stock)\n",
    "\n",
    "print(len(complete_stock_list))\n",
    "print(len(non_null_stocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33643293680092024164060"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.comb(2467, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have 2,467 available stocks and 33,643,293,680,092,024,164,060 options\n",
    "\n",
    "how do we choose?\n",
    "\n",
    "we'll come back to this but maybe the finance professor could help us pick..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here are some groups based on sectors/industries for now:\n",
    "1. Technology (Software & Hardware)\n",
    "- AAPL (Apple)\n",
    "- AMD (Advanced Micro Devices)\n",
    "- AKAM (Akamai Technologies)\n",
    "- AMZN (Amazon)\n",
    "- ADI (Analog Devices)\n",
    "- ADBE (Adobe)\n",
    "- ADSK (Autodesk)\n",
    "- ATVI (Activision Blizzard)\n",
    "2. Healthcare & Biotech\n",
    "- ABMD (Abiomed)\n",
    "- AMGN (Amgen)\n",
    "- BIIB (Biogen Idec)\n",
    "- AGN1 (Allergan)\n",
    "- BAX (Baxter International)\n",
    "- ABBV (AbbVie)\n",
    "- GILD (Gilead Sciences)\n",
    "- GSK (GlaxoSmithKline)\n",
    "3. Consumer Goods & Retail\n",
    "- COST (Costco)\n",
    "- WMT (Walmart)\n",
    "- HD (Home Depot)\n",
    "- MCD (McDonald's)\n",
    "- NKE (Nike)\n",
    "- TGT (Target)\n",
    "- LOW (Lowe’s)\n",
    "- F (Ford)\n",
    "4. Energy & Utilities\n",
    "- EOG (EOG Resources)\n",
    "- XOM (ExxonMobil)\n",
    "- COP (ConocoPhillips)\n",
    "- CVX (Chevron)\n",
    "- ENB (Enbridge)\n",
    "- WMB (Williams Companies)\n",
    "- OXY (Occidental Petroleum)\n",
    "- HES (Hess)\n",
    "5. Financials\n",
    "- JPM (JPMorgan Chase)\n",
    "- BAC (Bank of America)\n",
    "- GS (Goldman Sachs)\n",
    "- MS (Morgan Stanley)\n",
    "- AXP (American Express)\n",
    "- C (Citigroup)\n",
    "- PNC (PNC Financial Services)\n",
    "- WFC (Wells Fargo)\n",
    "6. Industrial & Manufacturing\n",
    "- CAT (Caterpillar)\n",
    "- GE (General Electric)\n",
    "- DE (Deere & Co.)\n",
    "- ITW (Illinois Tool Works)\n",
    "- MMM (3M)\n",
    "- UTX (United Technologies)\n",
    "- LMT (Lockheed Martin)\n",
    "- RTX (Raytheon Technologies)\n",
    "7. Consumer Services\n",
    "- DIS (Walt Disney)\n",
    "- CMCSA (Comcast)\n",
    "- AT&T (T)\n",
    "- SBUX (Starbucks)\n",
    "- LUV (Southwest Airlines)\n",
    "- DAL (Delta Air Lines)\n",
    "- UAL (United Airlines)\n",
    "- AAL (American Airlines)\n",
    "8. Real Estate\n",
    "- AVB (AvalonBay Communities)\n",
    "- SPG (Simon Property Group)\n",
    "- EQR (Equity Residential)\n",
    "- PLD (Prologis)\n",
    "- ESS (Essex Property Trust)\n",
    "- O (Realty Income)\n",
    "- NNN (National Retail Properties)\n",
    "- STAG (STAG Industrial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- calculate correlation matrix\n",
    "- cluster the matrix\n",
    "- perform these operations monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr_matrix(DataFrame):\n",
    "    return DataFrame.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster(df, num_clusters):\n",
    "    A = abs(df.corr().values)\n",
    "    D = np.diag(A.sum(axis=1))\n",
    "    L = D - A\n",
    "    eigenvalues, eigenvectors = LA.eig(L)\n",
    "    X = eigenvectors[:,:num_clusters]\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=2, n_init=20).fit(X)\n",
    "\n",
    "    cluster_dict = {}\n",
    "\n",
    "    # Iterate over the indices of cluster_list\n",
    "    for i in range(len(kmeans.labels_)):\n",
    "        cluster_number = kmeans.labels_[i]\n",
    "        stock_name = df.columns[i]\n",
    "\n",
    "        # Check if cluster_number is already a key in the dictionary\n",
    "        if cluster_number in cluster_dict:\n",
    "            cluster_dict[cluster_number].append(stock_name)\n",
    "        else:\n",
    "            cluster_dict[cluster_number] = [stock_name]\n",
    "    return cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_clustering(DataFrame, months_to_run):\n",
    "    # Set up the log\n",
    "    cluster_log = {}\n",
    "    # Get the list of timestamps (assuming the index is a list of Timestamps)\n",
    "    index = DataFrame.index.tolist()\n",
    "    # Start from the first timestamp\n",
    "    first_day = index[0]\n",
    "    #print(f\"Starting with first day: {first_day}\")\n",
    "    index_position = 0  # Keeps track of the current position in the list of timestamps\n",
    "    for _ in range(months_to_run):\n",
    "        # Calculate the last day of the month based on the current first day\n",
    "        last_day_of_month = pd.Timestamp(first_day.year, first_day.month, 1) + pd.offsets.MonthEnd(0)\n",
    "        #print(f\"Last day of month: {last_day_of_month}\") \n",
    "\n",
    "        # Cluster\n",
    "        cluster_entry = cluster(DataFrame[first_day:last_day_of_month], 3)\n",
    "        cluster_log[last_day_of_month] = cluster_entry\n",
    "        # Find the index position of the last day of the month in the list of timestamps\n",
    "        last_day_position = next(i for i, t in enumerate(index) if t.date() == last_day_of_month.date())\n",
    "        # Move to the next day after the last day of this month\n",
    "        first_day = index[last_day_position + 1]\n",
    "        #print(f\"Moving to the next first day: {first_day}\")\n",
    "    return cluster_log\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_sector_stocks = train_df[['AAPL','AMD','AKAM','AMZN','ADI','ADBE','ADSK','ATVI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Timestamp('2000-01-31 00:00:00'): {1: ['AAPL', 'ADSK', 'ATVI'],\n",
       "  0: ['AMD', 'AKAM', 'AMZN', 'ADI'],\n",
       "  2: ['ADBE']},\n",
       " Timestamp('2000-02-29 00:00:00'): {1: ['AAPL',\n",
       "   'AKAM',\n",
       "   'ADI',\n",
       "   'ADBE',\n",
       "   'ADSK',\n",
       "   'ATVI'],\n",
       "  2: ['AMD'],\n",
       "  0: ['AMZN']},\n",
       " Timestamp('2000-03-31 00:00:00'): {0: ['AAPL',\n",
       "   'AMD',\n",
       "   'AKAM',\n",
       "   'AMZN',\n",
       "   'ADBE',\n",
       "   'ATVI'],\n",
       "  2: ['ADI'],\n",
       "  1: ['ADSK']}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_clustering(tech_sector_stocks, 3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
