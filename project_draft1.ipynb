{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oT92rU-wgM6"
      },
      "source": [
        "# Import libraries, Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-fSDs9OAbBd",
        "outputId": "867ca323-894d-462c-8bcf-dbc72ea1a585"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#comment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "3CtM12jiwgM9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "import seaborn as sns\n",
        "import yfinance as yf\n",
        "from numpy import linalg as LA\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.stattools import coint\n",
        "from itertools import combinations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "IEsjifnLwgM-"
      },
      "outputs": [],
      "source": [
        "price_path = '/Users/tuckeringlefield/Desktop/FinanceData/price_data_from_shardar.csv'\n",
        "cap_path = '/Users/tuckeringlefield/Desktop/FinanceData/cap_data_from_shardar.csv'\n",
        "prices_df = pd.read_csv(price_path, index_col='date')\n",
        "caps_df = pd.read_csv(cap_path, index_col='date')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmDibaljwgM_",
        "outputId": "c3a57c1c-7132-4648-db11-6ce5d517feec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "# Convert dates to datetime\n",
        "prices_df.index = pd.to_datetime(prices_df.index)\n",
        "\n",
        "# Get the initial start and end date\n",
        "start_date = prices_df.index[0]\n",
        "end_date = prices_df.index[89]\n",
        "\n",
        "spy_data = yf.download('SPY', start=start_date, end=end_date, interval='1d')\n",
        "spy_data = pd.DataFrame(spy_data[\"Adj Close\"])\n",
        "spy_data.rename({\"Adj Close\": 'SPY'}, inplace=True, axis=1)\n",
        "spy_data = spy_data.reindex(prices_df.index)\n",
        "prices_with_market = pd.concat([prices_df, spy_data], axis=1)\n",
        "\n",
        "df_diff = prices_with_market.diff().dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSebSW-QwgM_",
        "outputId": "30a8c425-05e5-41d6-9c75-a290de5a9533"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5787\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "print(len(prices_with_market))\n",
        "print(len(df_diff))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGOC8KVEwgNA"
      },
      "source": [
        "# Outline and Function Definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNAFRVIrwgNA"
      },
      "source": [
        "Outline:\n",
        "\n",
        "We want to start from the year 2000 and do our analysis in two periods:\n",
        "\n",
        "- Learning Period\n",
        "\n",
        "This will require 3 months of data. The top ten largest market cap stocks will be calculated. We should check for null values, this will let us know what stocks were recently added. We can then remove/add stocks by relevency. We then should calculate the correlation matrix for these stocks off of the last day of the three months. Then we will do k means clustering to find pairs that are cointegrated based of off the ADF.\n",
        "\n",
        "- Testing Period\n",
        "\n",
        "This will operate on two weeks of data. We will look at the spread between the stocks. If the spread goes more than 2 std deviations away from the mean for the correlation matrix period we will suggest opening a trade. Spread will come from the linear regression coefficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gbTfemtwgNA"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "DpTMzuQhwgNA"
      },
      "outputs": [],
      "source": [
        "# Function to find the top ten largest market cap stocks\n",
        "def find_top_ten(dataframe, date_start, date_end):\n",
        "    # Filter dataframe over the desired 3 months\n",
        "    filtered_data = dataframe[date_start:date_end]\n",
        "    target_date = date_end + 1\n",
        "    selected_row = caps_df.iloc[target_date]\n",
        "    selected_row_no_null = selected_row.dropna()\n",
        "    stocks_list = selected_row_no_null.nlargest(10).index.tolist()\n",
        "    return stocks_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "emHDWAONwgNB"
      },
      "outputs": [],
      "source": [
        "# Function to check for null values\n",
        "def check_top_ten(dataframe, date_start, date_end, stocks_list):\n",
        "    #should find the average and median ammount of null values per column\n",
        "    #print this out and print out top ten col's ammounts\n",
        "    ammount_null = []\n",
        "    for column in df.columns:\n",
        "        num_null = df[column].isnull().sum()\n",
        "        ammount_null.append(num_null)\n",
        "    average_num_null = np.mean(ammount_null)\n",
        "    median_num_null = np.median(ammount_null)\n",
        "    plt.boxplot(ammount_null, vert=False)\n",
        "    plt.title('Boxplot of null values per stock in time period')\n",
        "    plt.show()\n",
        "    print(\"Checking Stocks List\")\n",
        "    print(\"--------------------\")\n",
        "    for column in stocks_list:\n",
        "        num_null = df[column].isnull().sum()\n",
        "        print(f'Stock: {column}, Num null: {num_null}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "D_pvBzyKwgNB"
      },
      "outputs": [],
      "source": [
        "# Function to filter the DF\n",
        "def filter_diff_df(dataframe, date_start, date_end, stocks_list):\n",
        "    desired_columns = stocks_list.copy()\n",
        "    desired_columns.append(\"SPY\")\n",
        "    #print(desired_columns)\n",
        "    filtered_df = dataframe[desired_columns]\n",
        "    filtered_df = filtered_df[date_start:date_end].diff()#.dropna()\n",
        "    print(len(filtered_df))\n",
        "    print(filtered_df.isnull().sum())\n",
        "    filtered_df = filtered_df.dropna()\n",
        "    print(len(filtered_df))\n",
        "    return filtered_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ZAAAIg6cGmZZ"
      },
      "outputs": [],
      "source": [
        "def filter_df_by_dates(dataframe, date_start, date_end, stocks_list):\n",
        "    desired_columns = stocks_list.copy()\n",
        "    desired_columns.append(\"SPY\")\n",
        "    filtered_df = dataframe[desired_columns]\n",
        "    filtered_df = filtered_df[date_start:date_end]\n",
        "    return filtered_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "WiM0K2fHwgNB"
      },
      "outputs": [],
      "source": [
        "# Function to calculate the betas\n",
        "def calculate_betas(dataframe, date_start, date_end, stocks_list):\n",
        "    df = dataframe[date_start:date_end]\n",
        "    beta_values = []\n",
        "    columns = []\n",
        "\n",
        "    df_var = df['SPY'].var()\n",
        "\n",
        "    for stk in stocks_list:\n",
        "        df_cov = df[[stk, 'SPY']].cov().loc[stk, 'SPY']\n",
        "        beta = df_cov / df_var\n",
        "        beta_values.append(beta)\n",
        "        columns.append(stk + '_beta')\n",
        "\n",
        "    beta_df = pd.DataFrame([beta_values], columns=columns)\n",
        "    beta_df.index = df.index[:1]\n",
        "\n",
        "    # plt.figure(figsize=(12, 4))\n",
        "    # sns.boxplot(data=beta_df)\n",
        "    # plt.show()\n",
        "\n",
        "    return beta_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "BJMfpPXJwgNB"
      },
      "outputs": [],
      "source": [
        "# Function to calculate the residuals\n",
        "def calculate_residuals(df, stocks_list):\n",
        "    res_df = pd.DataFrame()\n",
        "    for stk in stocks_list:\n",
        "        res_df[stk] = df[stk]-df[stk+\"_beta\"]*df[\"SPY\"]\n",
        "    return res_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "pIRNkEFVwgNC"
      },
      "outputs": [],
      "source": [
        "# Function to cluster the matrix\n",
        "def cluster_the_matrix(df, num_clusters):\n",
        "    A = abs(df.corr().values)\n",
        "    #print(f'A Shape: {A.shape}')\n",
        "    D = np.diag(A.sum(axis=1))\n",
        "    #print(f'D Shape: {D.shape}')\n",
        "    L = D - A\n",
        "    #print(f'L Shape: {L.shape}')\n",
        "    eigenvalues, eigenvectors = LA.eig(L)\n",
        "    X = eigenvectors[:,:num_clusters]\n",
        "    #print(f'X Shape: {X.shape}')\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=2, n_init=20).fit(X)\n",
        "    #print(\"Kmeans Labels:\")\n",
        "    #print(kmeans.labels_)\n",
        "    #print(df.columns)\n",
        "\n",
        "    cluster_dict = {}\n",
        "\n",
        "    # Iterate over the indices of cluster_list\n",
        "    for i in range(len(kmeans.labels_)):\n",
        "        cluster_number = kmeans.labels_[i]\n",
        "        stock_name = df.columns[i]\n",
        "\n",
        "        # Check if cluster_number is already a key in the dictionary\n",
        "        if cluster_number in cluster_dict:\n",
        "            cluster_dict[cluster_number].append(stock_name)\n",
        "        else:\n",
        "            cluster_dict[cluster_number] = [stock_name]\n",
        "\n",
        "    # fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
        "    # scatter = ax.scatter(X[:, 0], X[:, 1], c=kmeans.labels_)\n",
        "    # unique_labels = {label: idx for idx, label in enumerate(set(kmeans.labels_))}\n",
        "    # handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=scatter.cmap(scatter.norm(value)), markersize=10)\n",
        "    #        for value in unique_labels.values()]\n",
        "    # labels = unique_labels.keys()\n",
        "    # ax.legend(handles, labels, title=\"Clusters\", loc=\"best\", bbox_to_anchor=(1, 1))\n",
        "    # ax.set_title(f'K-Means Clustering Results with K={num_clusters}')\n",
        "    # plt.show()\n",
        "\n",
        "    return cluster_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "uy5WxWWnwgNC"
      },
      "outputs": [],
      "source": [
        "# Function to find the cointegrated pairs\n",
        "def find_cointegrated_pairs(dataframe, cluster_dict, sig_level):\n",
        "    cointegrated_pairs = []\n",
        "    for cluster_num, stocks in cluster_dict.items():\n",
        "      for stock1, stock2 in combinations(stocks, 2):\n",
        "          pvalue1 = coint(dataframe[stock1], dataframe[stock2])[1]\n",
        "          pvalue2 = coint(dataframe[stock2], dataframe[stock1])[1]\n",
        "          if pvalue1 < sig_level and pvalue2 < sig_level:\n",
        "              cointegrated_pairs.append((stock1, stock2))\n",
        "    return cointegrated_pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to check on existing pairs\n",
        "def is_still_conintegrated(dataframe, pair, sig_level):\n",
        "    stock1 = pair[0]\n",
        "    stock2 = pair[1]\n",
        "    pvalue1 = coint(dataframe[stock1], dataframe[stock2])[1]\n",
        "    pvalue2 = coint(dataframe[stock2], dataframe[stock1])[1]\n",
        "    if pvalue1 < sig_level and pvalue2 < sig_level:\n",
        "        return True\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# weekly function to calculate the beta of the pair\n",
        "def calculate_beta_for_pair(dataframe, pair):\n",
        "    asst1 = pair[0]\n",
        "    asst2 = pair[1]\n",
        "\n",
        "    train = dataframe[[asst1, asst2]]\n",
        "\n",
        "    beta = train.cov().iloc[0, 1]/train[asst2].var()\n",
        "    return beta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to get the spread data\n",
        "def get_spread_limits_for_past_months(dataframe, pair, beta):\n",
        "    asst1 = pair[0]\n",
        "    asst2 = pair[1]\n",
        "    asst1_mean = dataframe[asst1].mean() \n",
        "    asst2_mean = dataframe[asst2].mean() \n",
        "    spread_data = None\n",
        "    order = []\n",
        "    if asst1_mean > asst2_mean:\n",
        "        spread_data = dataframe[asst1]-beta*dataframe[asst2]\n",
        "        order = [asst1, asst2]\n",
        "    else:\n",
        "        spread_data = dataframe[asst2]-beta*dataframe[asst1]\n",
        "        order = [asst2, asst1]\n",
        "    mean = spread_data.mean()\n",
        "    std_dev = spread_data.std()\n",
        "    lower_limit = mean - (2*std_dev)\n",
        "    upper_limit = mean + (2*std_dev)\n",
        "    \n",
        "    return upper_limit, lower_limit, order\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Monitor a pair for a week\n",
        "\n",
        "def monitor_pair_for_week(dataframe, start_date_index, end_date_index, curr_week_start_index, pair, pair_vals_list):\n",
        "    #[ still_consecutive, [start_dates], [end_date], [[days_to_open_trade]] ]\n",
        "    global prices_with_market\n",
        "    start_date_string = prices_with_market.index[start_date_index].strftime('%Y-%m-%d')\n",
        "    end_date_string = prices_with_market.index[end_date_index].strftime('%Y-%m-%d')\n",
        "    curr_week_date_string = prices_with_market.index[curr_week_start_index].strftime('%Y-%m-%d')\n",
        "    forward_three_months_data = prices_with_market[start_date_index+7 : end_date_index]\n",
        "\n",
        "    if pair_vals_list[0] == True:\n",
        "        past_three_month_data = prices_with_market[start_date_index : curr_week_start_index]\n",
        "        beta_past_three_months = calculate_beta_for_pair(past_three_month_data, pair)\n",
        "        upper, lower , pair_order = get_spread_limits_for_past_months(past_three_month_data, pair, beta_past_three_months)\n",
        "        curr_week_data = dataframe.tail(7)\n",
        "        curr_week_spread_data = curr_week_data[pair_order[0]]-beta_past_three_months*curr_week_data[pair_order[1]]\n",
        "        for index, value in zip(curr_week_spread_data.index, curr_week_spread_data.values):\n",
        "            date = index.strftime('%Y-%m-%d')\n",
        "            if (value >= upper or value <= lower):\n",
        "                pair_vals_list[-1][-1].append(date)\n",
        "        \n",
        "    \n",
        "    is_coint = is_still_conintegrated(forward_three_months_data, pair , sig_level=0.05)\n",
        "    if is_coint:\n",
        "        if pair_vals_list[0] == False:\n",
        "            pair_vals_list[1].append(curr_week_date_string)\n",
        "            pair_vals_list[-1].append([])\n",
        "            pair_vals_list[0] = True\n",
        "    else:\n",
        "        if pair_vals_list[0] == True:\n",
        "            pair_vals_list[0] = False\n",
        "            pair_vals_list[2].append(curr_week_date_string)\n",
        "\n",
        "    return pair_vals_list\n",
        "\n",
        "# start date ['2000-03-02', '2000-05-07']\n",
        "# end date ['2000-03-28', '']\n",
        "# trading days [ ['2000-03-15'], []]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [],
      "source": [
        "def monitor_group_of_pairs(dataframe, pair_dict, stop_after_weeks):\n",
        "    coint_dict = pair_dict.copy()\n",
        "    weeks_running = 0\n",
        "    while(weeks_running < stop_after_weeks):\n",
        "        # On the first week we don't have any previous data in the pair_dict What do we pass in??? \n",
        "        start_date_index = ((weeks_running+1)*7)\n",
        "        # always add 89 days here\n",
        "        end_date_index = ((weeks_running+1)*7) + 97\n",
        "\n",
        "        curr_week_start_index = ((weeks_running+1)*7) + 89\n",
        "        # Filter the overall df\n",
        "        three_month_plus_one_week_df = dataframe[start_date_index : end_date_index]\n",
        "        for key, value in coint_dict.items():\n",
        "            # end_date = start_date + WEEK            \n",
        "            result = monitor_pair_for_week(three_month_plus_one_week_df, start_date_index, end_date_index, curr_week_start_index, key, value )\n",
        "            # Update pair_dict[pair] with result\n",
        "            coint_dict[key] = result\n",
        "        # Prepping for the next week...\n",
        "        \n",
        "        # Finding the new cointegrated pairs\n",
        "        print(\"New Week\")\n",
        "        new_top_ten_stocks = find_top_ten(prices_with_market, (start_date_index) , (end_date_index))\n",
        "        monitoring_data = filter_diff_df(prices_with_market, (start_date_index) , (end_date_index), new_top_ten_stocks)\n",
        "        print(f'Monitoring data: {len(monitoring_data)}')\n",
        "        filtered_monitoring_data = filter_df_by_dates(prices_with_market, (start_date_index+7) , end_date_index, new_top_ten_stocks)\n",
        "        print(f'Filtered Monitoring data: {len(filtered_monitoring_data)}')\n",
        "        beta_df = calculate_betas(filtered_monitoring_data, (start_date_index+7) , end_date_index, new_top_ten_stocks)\n",
        "        print(f'beta data: {len(beta_df)}')\n",
        "        print(\"-------------------------\")\n",
        "\n",
        "        merged_df = filtered_monitoring_data.merge(beta_df, how = 'cross')\n",
        "        res_df = calculate_residuals(merged_df, new_top_ten_stocks)\n",
        "        cluster_dict = cluster_the_matrix(res_df, 5)\n",
        "        pairs = find_cointegrated_pairs(filtered_monitoring_data, cluster_dict, 0.05)\n",
        "        #print(pairs)\n",
        "        \n",
        "        #found_pairs = find_contintegrated_pairs() \n",
        "        default_val_list_for_new_pair = [True, [dataframe.index[start_date_index]],[],[[]]]\n",
        "        # for item in found_pairs:\n",
        "            #if coint_dict[item] not in coint_dict:\n",
        "                #otherwise add it as a new key with the default list\n",
        "        weeks_running += 1\n",
        "    return coint_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xgVEn93wgNC"
      },
      "source": [
        "# Testing Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "a08q3r-ywgNC",
        "outputId": "7ddda714-7da1-4d44-a201-d7dbb29eb8da"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ATW</th>\n",
              "      <th>A</th>\n",
              "      <th>AA</th>\n",
              "      <th>AAAB</th>\n",
              "      <th>AABC</th>\n",
              "      <th>AAC1</th>\n",
              "      <th>AACC</th>\n",
              "      <th>AACE</th>\n",
              "      <th>AACH</th>\n",
              "      <th>AADI</th>\n",
              "      <th>...</th>\n",
              "      <th>ZVOI</th>\n",
              "      <th>ZVRA</th>\n",
              "      <th>ZVUE</th>\n",
              "      <th>ZVXI</th>\n",
              "      <th>ZY</th>\n",
              "      <th>ZYME</th>\n",
              "      <th>ZYNE</th>\n",
              "      <th>ZYXI</th>\n",
              "      <th>ZZ</th>\n",
              "      <th>SPY</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-01-03</th>\n",
              "      <td>8.766</td>\n",
              "      <td>44.275</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.036</td>\n",
              "      <td>7.791</td>\n",
              "      <td>4.562</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17.000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.625</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>93.290169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-04</th>\n",
              "      <td>8.913</td>\n",
              "      <td>40.893</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.619</td>\n",
              "      <td>7.791</td>\n",
              "      <td>4.438</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>89.641953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-05</th>\n",
              "      <td>8.899</td>\n",
              "      <td>37.855</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.500</td>\n",
              "      <td>7.791</td>\n",
              "      <td>4.438</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.125</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.708</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>89.802322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-06</th>\n",
              "      <td>9.270</td>\n",
              "      <td>36.896</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.500</td>\n",
              "      <td>7.791</td>\n",
              "      <td>4.500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.125</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.833</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.359055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-07</th>\n",
              "      <td>9.508</td>\n",
              "      <td>39.971</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.738</td>\n",
              "      <td>7.607</td>\n",
              "      <td>4.562</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.750</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.167</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>93.490654</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 10811 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              ATW       A  AA   AAAB   AABC   AAC1  AACC    AACE  AACH  AADI  \\\n",
              "date                                                                           \n",
              "2000-01-03  8.766  44.275 NaN  8.036  7.791  4.562   NaN  17.000   NaN   NaN   \n",
              "2000-01-04  8.913  40.893 NaN  7.619  7.791  4.438   NaN  15.875   NaN   NaN   \n",
              "2000-01-05  8.899  37.855 NaN  7.500  7.791  4.438   NaN  16.125   NaN   NaN   \n",
              "2000-01-06  9.270  36.896 NaN  7.500  7.791  4.500   NaN  16.125   NaN   NaN   \n",
              "2000-01-07  9.508  39.971 NaN  7.738  7.607  4.562   NaN  16.750   NaN   NaN   \n",
              "\n",
              "            ...  ZVOI  ZVRA  ZVUE   ZVXI  ZY  ZYME  ZYNE  ZYXI  ZZ        SPY  \n",
              "date        ...                                                                \n",
              "2000-01-03  ...   NaN   NaN   NaN  3.625 NaN   NaN   NaN   NaN NaN  93.290169  \n",
              "2000-01-04  ...   NaN   NaN   NaN  3.500 NaN   NaN   NaN   NaN NaN  89.641953  \n",
              "2000-01-05  ...   NaN   NaN   NaN  3.708 NaN   NaN   NaN   NaN NaN  89.802322  \n",
              "2000-01-06  ...   NaN   NaN   NaN  3.833 NaN   NaN   NaN   NaN NaN  88.359055  \n",
              "2000-01-07  ...   NaN   NaN   NaN  4.167 NaN   NaN   NaN   NaN NaN  93.490654  \n",
              "\n",
              "[5 rows x 10811 columns]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prices_with_market.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WlBV2KDwgNC",
        "outputId": "2e9868c6-39a8-4e14-e072-274de239d1a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['SCMR', 'LVLT', 'AMAT', 'INTC', 'CSCO', 'JAVA1', 'ORCL', 'DELL1', 'MSFT', 'QCOM']\n"
          ]
        }
      ],
      "source": [
        "start = prices_with_market.index[0]\n",
        "end = prices_with_market.index[89]\n",
        "top_ten = find_top_ten(prices_with_market, start, end)\n",
        "\n",
        "print(top_ten)\n",
        "# check_top_ten(df, start, end, top_ten)\n",
        "# print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKCMtBTOwgNC",
        "outputId": "f99d96e1-8147-4d7c-cd1b-ea013660462b"
      },
      "outputs": [],
      "source": [
        "filtered_diff_df = filter_diff_df(prices_with_market, start, end, top_ten)\n",
        "filtered_diff_df.head()\n",
        "three_month_top_10_price_df = filter_df_by_dates(prices_with_market, start, end, top_ten)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S3lbVsBywgNC",
        "outputId": "9e053ff6-2b61-494d-e3c8-9e648e45a58a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beta DF:\n",
            "            SCMR_beta  LVLT_beta  AMAT_beta  INTC_beta  CSCO_beta  JAVA1_beta  \\\n",
            "date                                                                            \n",
            "2000-01-04  18.534859  16.697715   0.505715    0.47547   0.684213    2.472605   \n",
            "\n",
            "            ORCL_beta  DELL1_beta  MSFT_beta  QCOM_beta  \n",
            "date                                                     \n",
            "2000-01-04   0.508758    0.451121   0.329183   0.901148  \n",
            "\n",
            "Residual DF:\n",
            "          SCMR       LVLT      AMAT      INTC      CSCO      JAVA1      ORCL  \\\n",
            "0    18.035173 -27.133127  0.701956  0.566617  0.393155  -0.479401 -0.275942   \n",
            "1   -38.805433 -36.427810 -1.021101  0.409749  0.166273  -0.146531 -0.942589   \n",
            "2   -69.082235 -22.850726  0.858881 -1.005770  0.022502  -4.181368 -0.802727   \n",
            "3    13.219529 -54.635982 -2.411124 -1.504921 -1.477105  -4.938420 -1.093740   \n",
            "4     9.055558  55.544761  1.589809  0.927509  1.124561  12.831994  2.377833   \n",
            "..         ...        ...       ...       ...       ...        ...       ...   \n",
            "83  -12.898310 -63.210512  0.496565  0.435925  0.147965   3.616360  0.284170   \n",
            "84   11.710626  -3.909103  0.853459 -0.180876 -2.143504  -5.189465 -0.986620   \n",
            "85   47.638970  62.244511  0.971049  0.568477  2.084760   7.017103  0.486685   \n",
            "86   10.975752 -33.422993 -1.939374 -1.340343 -2.972616  -8.535671 -1.491264   \n",
            "87 -108.279301  19.748116 -1.494048  0.146767  0.501884  -4.686293  0.246184   \n",
            "\n",
            "       DELL1      MSFT      QCOM  \n",
            "0  -2.387215 -0.023068 -2.274415  \n",
            "1   3.071654  0.317209 -1.470517  \n",
            "2  -1.187912 -0.708900 -4.487401  \n",
            "3  -4.034970 -1.241237 -1.423333  \n",
            "4  -2.101682  0.145425  2.750986  \n",
            "..       ...       ...       ...  \n",
            "83  0.505079  0.928435  1.049786  \n",
            "84 -2.266239 -0.261922 -1.973731  \n",
            "85  1.992390 -0.152837  0.006987  \n",
            "86 -1.525225 -0.178768 -1.574208  \n",
            "87 -0.737094 -0.379537  1.307011  \n",
            "\n",
            "[88 rows x 10 columns]\n"
          ]
        }
      ],
      "source": [
        "beta_df = calculate_betas(filtered_diff_df, start, end, top_ten)\n",
        "print('Beta DF:')\n",
        "print(beta_df)\n",
        "print()\n",
        "\n",
        "merged_df = filtered_diff_df.merge(beta_df, how = 'cross')\n",
        "\n",
        "print('Residual DF:')\n",
        "res_df = calculate_residuals(merged_df, top_ten)\n",
        "print(res_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "C9zbM6uEwgNC",
        "outputId": "774f501a-4a96-4761-ad7c-a1ae0c8a06df"
      },
      "outputs": [],
      "source": [
        "cluster_dictionary_for_top_10 = cluster_the_matrix(res_df, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5RXYjkkwgNC",
        "outputId": "4948c41d-5fb9-43e3-8f66-9fcd55122c46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('INTC', 'ORCL')]"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "coint_pairs_from_top_10 = find_cointegrated_pairs(three_month_top_10_price_df, cluster_dictionary_for_top_10, 0.05)\n",
        "coint_pairs_from_top_10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "pair_dict = {\n",
        "        # [ still_consecutive, [start_dates], [end_date], times_correct, weeks_counted, curr_accuracy, [accuracy] ]\n",
        "        ('INTC', 'ORCL') : [ True, ['2000-04-4'], [], 0, 0, 0, [] ]\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "date\n",
              "2000-01-03    24.208\n",
              "2000-01-04    22.076\n",
              "2000-01-05    21.215\n",
              "2000-01-06    19.678\n",
              "2000-01-07    21.195\n",
              "               ...  \n",
              "2000-05-04    30.439\n",
              "2000-05-05    31.488\n",
              "2000-05-08    29.644\n",
              "2000-05-09    29.517\n",
              "2000-05-10    27.725\n",
              "Name: ORCL, Length: 90, dtype: float64"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "three_month_top_10_price_df['ORCL']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "date\n",
              "2000-01-03    25.042\n",
              "2000-01-04    23.874\n",
              "2000-01-05    24.360\n",
              "2000-01-06    22.668\n",
              "2000-01-07    23.603\n",
              "               ...  \n",
              "2000-05-04    34.445\n",
              "2000-05-05    35.539\n",
              "2000-05-08    33.869\n",
              "2000-05-09    33.667\n",
              "2000-05-10    30.557\n",
              "Name: INTC, Length: 90, dtype: float64"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "three_month_top_10_price_df['INTC']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "date\n",
            "2000-01-03   -0.123972\n",
            "2000-01-04   -1.121089\n",
            "2000-01-05   -2.454310\n",
            "2000-01-06   -2.347284\n",
            "2000-01-07   -1.738773\n",
            "                ...   \n",
            "2000-05-04   -3.029365\n",
            "2000-05-05   -3.043346\n",
            "2000-05-08   -3.264696\n",
            "2000-05-09   -3.195424\n",
            "2000-05-10   -1.965603\n",
            "Length: 90, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "asst1 = 'ORCL'\n",
        "asst2 = 'INTC'\n",
        "\n",
        "train = three_month_top_10_price_df[[asst1, asst2]]\n",
        "\n",
        "beta = train.cov().iloc[0, 1]/train[asst2].var()\n",
        "train_spread = train[asst1]-beta*train[asst2]\n",
        "#test_spread = test[asst1]-beta*test[asst2]\n",
        "\n",
        "print(train_spread)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              ORCL    INTC\n",
            "date                      \n",
            "2000-01-03  24.208  25.042\n",
            "2000-01-04  22.076  23.874\n",
            "2000-01-05  21.215  24.360\n",
            "2000-01-06  19.678  22.668\n",
            "2000-01-07  21.195  23.603\n",
            "\n",
            "-1.9656030991385762\n",
            "-2.6770280125542634\n",
            "-1.76693316240042\n",
            "-1.482613516084708\n",
            "-1.6475948228379096\n",
            "-2.4219622725933476\n",
            "-4.720263225662265\n"
          ]
        }
      ],
      "source": [
        "days_to_monitor = 7\n",
        "\n",
        "whole_data = prices_with_market[[asst1,asst2]]\n",
        "print(whole_data.head())\n",
        "print()\n",
        "\n",
        "date_to_start = whole_data.index[89]\n",
        "for day in range(days_to_monitor):\n",
        "    current_date = pd.to_datetime(whole_data.index[89 + day]).strftime(\"%Y-%m-%d\")\n",
        "    day_df = whole_data.loc[current_date]\n",
        "    train_spread = day_df[asst1]-beta*day_df[asst2]\n",
        "    print(train_spread)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New Week\n",
            "97\n",
            "SCMR      1\n",
            "LVLT      1\n",
            "CSCO      1\n",
            "ORCL      1\n",
            "QCOM      1\n",
            "JAVA1     1\n",
            "MSFT      1\n",
            "VIAV      1\n",
            "INTC      1\n",
            "SDLI      1\n",
            "SPY      16\n",
            "dtype: int64\n",
            "81\n",
            "Monitoring data: 81\n",
            "Filtered Monitoring data: 90\n",
            "beta data: 1\n",
            "-------------------------\n",
            "New Week\n",
            "97\n",
            "SCMR      1\n",
            "SDLI      1\n",
            "LVLT      1\n",
            "RMBS      1\n",
            "CSCO      1\n",
            "INTC      1\n",
            "VIAV      1\n",
            "AMCC      1\n",
            "JAVA1     1\n",
            "ORCL      1\n",
            "SPY      23\n",
            "dtype: int64\n",
            "74\n",
            "Monitoring data: 74\n",
            "Filtered Monitoring data: 90\n",
            "beta data: 1\n",
            "-------------------------\n",
            "New Week\n",
            "97\n",
            "SCMR      1\n",
            "RMBS      1\n",
            "MSFT      1\n",
            "LVLT      1\n",
            "QCOM      1\n",
            "SDLI      1\n",
            "BBRC1     1\n",
            "ORCL      1\n",
            "CSCO      1\n",
            "VIAV      1\n",
            "SPY      30\n",
            "dtype: int64\n",
            "67\n",
            "Monitoring data: 67\n",
            "Filtered Monitoring data: 90\n",
            "beta data: 1\n",
            "-------------------------\n",
            "New Week\n",
            "97\n",
            "SCMR     1\n",
            "BRCM     1\n",
            "ORCL     1\n",
            "VIAV     1\n",
            "CSCO     1\n",
            "SDLI     1\n",
            "INTC     1\n",
            "LVLT     1\n",
            "ISLD     1\n",
            "MSFT     1\n",
            "SPY     37\n",
            "dtype: int64\n",
            "60\n",
            "Monitoring data: 60\n",
            "Filtered Monitoring data: 90\n",
            "beta data: 1\n",
            "-------------------------\n",
            "New Week\n",
            "97\n",
            "SCMR     1\n",
            "ARBA     1\n",
            "CSCO     1\n",
            "PMCS     1\n",
            "AMCC     1\n",
            "MSFT     1\n",
            "SDLI     1\n",
            "INTC     1\n",
            "VIAV     1\n",
            "MSI      1\n",
            "SPY     44\n",
            "dtype: int64\n",
            "53\n",
            "Monitoring data: 53\n",
            "Filtered Monitoring data: 90\n",
            "beta data: 1\n",
            "-------------------------\n",
            "New Week\n",
            "97\n",
            "SCMR      1\n",
            "SDLI      1\n",
            "VIAV      1\n",
            "LVLT      1\n",
            "VSTR1     1\n",
            "JAVA1     1\n",
            "DELL1     1\n",
            "INTC      1\n",
            "CSCO      1\n",
            "LU1       1\n",
            "SPY      51\n",
            "dtype: int64\n",
            "46\n",
            "Monitoring data: 46\n",
            "Filtered Monitoring data: 90\n",
            "beta data: 1\n",
            "-------------------------\n"
          ]
        },
        {
          "ename": "LinAlgError",
          "evalue": "Array must not contain infs or NaNs",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[129], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m pair_dict \u001b[39m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m         \u001b[39m# [ still_consecutive, [start_dates], [end_date] weeks_counted, [[days_to_open_trade]] ]\u001b[39;00m\n\u001b[1;32m      3\u001b[0m         (\u001b[39m'\u001b[39m\u001b[39mINTC\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mORCL\u001b[39m\u001b[39m'\u001b[39m) : [ \u001b[39mTrue\u001b[39;00m, [\u001b[39m'\u001b[39m\u001b[39m2000-04-4\u001b[39m\u001b[39m'\u001b[39m], [], [] ]\n\u001b[1;32m      4\u001b[0m     }\n\u001b[0;32m----> 5\u001b[0m monitor_group_of_pairs(prices_with_market, pair_dict, \u001b[39m200\u001b[39;49m)\n\u001b[1;32m      6\u001b[0m \u001b[39m# We know it's working right but we are corcerned about the is_coint function elimating possible trade days?\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[123], line 33\u001b[0m, in \u001b[0;36mmonitor_group_of_pairs\u001b[0;34m(dataframe, pair_dict, stop_after_weeks)\u001b[0m\n\u001b[1;32m     31\u001b[0m merged_df \u001b[39m=\u001b[39m filtered_monitoring_data\u001b[39m.\u001b[39mmerge(beta_df, how \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcross\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     32\u001b[0m res_df \u001b[39m=\u001b[39m calculate_residuals(merged_df, new_top_ten_stocks)\n\u001b[0;32m---> 33\u001b[0m cluster_dict \u001b[39m=\u001b[39m cluster_the_matrix(res_df, \u001b[39m5\u001b[39;49m)\n\u001b[1;32m     34\u001b[0m pairs \u001b[39m=\u001b[39m find_cointegrated_pairs(filtered_monitoring_data, cluster_dict, \u001b[39m0.05\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[39m#print(pairs)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[39m#found_pairs = find_contintegrated_pairs() \u001b[39;00m\n",
            "Cell \u001b[0;32mIn[93], line 9\u001b[0m, in \u001b[0;36mcluster_the_matrix\u001b[0;34m(df, num_clusters)\u001b[0m\n\u001b[1;32m      7\u001b[0m L \u001b[39m=\u001b[39m D \u001b[39m-\u001b[39m A\n\u001b[1;32m      8\u001b[0m \u001b[39m#print(f'L Shape: {L.shape}')\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m eigenvalues, eigenvectors \u001b[39m=\u001b[39m LA\u001b[39m.\u001b[39;49meig(L)\n\u001b[1;32m     10\u001b[0m X \u001b[39m=\u001b[39m eigenvectors[:,:num_clusters]\n\u001b[1;32m     11\u001b[0m \u001b[39m#print(f'X Shape: {X.shape}')\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/linalg/linalg.py:1329\u001b[0m, in \u001b[0;36meig\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   1327\u001b[0m _assert_stacked_2d(a)\n\u001b[1;32m   1328\u001b[0m _assert_stacked_square(a)\n\u001b[0;32m-> 1329\u001b[0m _assert_finite(a)\n\u001b[1;32m   1330\u001b[0m t, result_t \u001b[39m=\u001b[39m _commonType(a)\n\u001b[1;32m   1332\u001b[0m extobj \u001b[39m=\u001b[39m get_linalg_error_extobj(\n\u001b[1;32m   1333\u001b[0m     _raise_linalgerror_eigenvalues_nonconvergence)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/linalg/linalg.py:218\u001b[0m, in \u001b[0;36m_assert_finite\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m arrays:\n\u001b[1;32m    217\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m isfinite(a)\u001b[39m.\u001b[39mall():\n\u001b[0;32m--> 218\u001b[0m         \u001b[39mraise\u001b[39;00m LinAlgError(\u001b[39m\"\u001b[39m\u001b[39mArray must not contain infs or NaNs\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mLinAlgError\u001b[0m: Array must not contain infs or NaNs"
          ]
        }
      ],
      "source": [
        "pair_dict = {\n",
        "        # [ still_consecutive, [start_dates], [end_date] weeks_counted, [[days_to_open_trade]] ]\n",
        "        ('INTC', 'ORCL') : [ True, ['2000-04-4'], [], [] ]\n",
        "    }\n",
        "monitor_group_of_pairs(prices_with_market, pair_dict, 200)\n",
        "# We know it's working right but we are corcerned about the is_coint function elimating possible trade days?\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
