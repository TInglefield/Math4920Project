{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports, Setup, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from numpy import linalg as LA\n",
    "from sklearn.cluster import KMeans\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from itertools import combinations\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "import random\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATW</th>\n",
       "      <th>A</th>\n",
       "      <th>AA</th>\n",
       "      <th>AAAB</th>\n",
       "      <th>AABC</th>\n",
       "      <th>AAC1</th>\n",
       "      <th>AACC</th>\n",
       "      <th>AACE</th>\n",
       "      <th>AACH</th>\n",
       "      <th>AADI</th>\n",
       "      <th>...</th>\n",
       "      <th>ZVIA</th>\n",
       "      <th>ZVOI</th>\n",
       "      <th>ZVRA</th>\n",
       "      <th>ZVUE</th>\n",
       "      <th>ZVXI</th>\n",
       "      <th>ZY</th>\n",
       "      <th>ZYME</th>\n",
       "      <th>ZYNE</th>\n",
       "      <th>ZYXI</th>\n",
       "      <th>ZZ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>0.265785</td>\n",
       "      <td>14.803789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.074688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>0.355094</td>\n",
       "      <td>13.938379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>0.597657</td>\n",
       "      <td>15.593232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082724</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>0.377474</td>\n",
       "      <td>6.688876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>0.698268</td>\n",
       "      <td>8.061751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.061952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 10806 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ATW          A  AA      AAAB      AABC      AAC1  AACC  \\\n",
       "date                                                                      \n",
       "2000-01-03  0.265785  14.803789 NaN  0.002968  0.000000  0.055383   NaN   \n",
       "2000-01-04  0.355094  13.938379 NaN  0.001050  0.000000  0.093997   NaN   \n",
       "2000-01-05  0.597657  15.593232 NaN  0.002262  0.000000  0.082724   NaN   \n",
       "2000-01-06  0.377474   6.688876 NaN  0.003307  0.000000  0.071145   NaN   \n",
       "2000-01-07  0.698268   8.061751 NaN  0.001843  0.000426  0.061952   NaN   \n",
       "\n",
       "                AACE  AACH  AADI  ...  ZVIA  ZVOI  ZVRA  ZVUE      ZVXI  ZY  \\\n",
       "date                              ...                                         \n",
       "2000-01-03  0.074688   NaN   NaN  ...   NaN   NaN   NaN   NaN  0.010821 NaN   \n",
       "2000-01-04  0.036322   NaN   NaN  ...   NaN   NaN   NaN   NaN  0.001050 NaN   \n",
       "2000-01-05  0.042248   NaN   NaN  ...   NaN   NaN   NaN   NaN  0.002725 NaN   \n",
       "2000-01-06  0.022496   NaN   NaN  ...   NaN   NaN   NaN   NaN  0.006309 NaN   \n",
       "2000-01-07  0.005193   NaN   NaN  ...   NaN   NaN   NaN   NaN  0.033459 NaN   \n",
       "\n",
       "            ZYME  ZYNE  ZYXI  ZZ  \n",
       "date                              \n",
       "2000-01-03   NaN   NaN   NaN NaN  \n",
       "2000-01-04   NaN   NaN   NaN NaN  \n",
       "2000-01-05   NaN   NaN   NaN NaN  \n",
       "2000-01-06   NaN   NaN   NaN NaN  \n",
       "2000-01-07   NaN   NaN   NaN NaN  \n",
       "\n",
       "[5 rows x 10806 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap_path = '/Users/tuckeringlefield/Desktop/Data_Science/Math_4920/Stocks_Data/cap_data_from_shardar.csv'\n",
    "price_path = \"/Users/tuckeringlefield/Desktop/Data_Science/Math_4920/Stocks_Data/price_data_from_shardar.csv\"\n",
    "\n",
    "# Reading Data:\n",
    "prices_df = pd.read_csv(price_path, index_col='date')\n",
    "caps_df = pd.read_csv(cap_path, index_col='date')\n",
    "\n",
    "# Drop troubled stock...\n",
    "prices_df.drop([\"MGI\", \"MDLZ\", \"DWA\", \"ICE\"], axis=1, inplace=True)\n",
    "caps_df.drop([\"MGI\", \"MDLZ\", \"DWA\", \"ICE\"], axis=1, inplace=True)\n",
    "\n",
    "prices_df.head()\n",
    "caps_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "prices_df.index = pd.to_datetime(prices_df.index)\n",
    "\n",
    "# Get the initial start and end date\n",
    "start_date = prices_df.index[0]\n",
    "end_date = prices_df.index[-1]\n",
    "\n",
    "# Download additional data:\n",
    "spy_data = yf.download('SPY', start=start_date, end=end_date, interval='1d')\n",
    "spy_data = pd.DataFrame(spy_data[\"Adj Close\"])\n",
    "spy_data.rename({\"Adj Close\": 'SPY'}, inplace=True, axis=1)\n",
    "\n",
    "# Set up dataframes:\n",
    "prices_with_market = prices_df.merge(spy_data, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Length: 5787\n",
      "Train Length: 2894\n"
     ]
    }
   ],
   "source": [
    "# Pulling rougly the first half of data\n",
    "num_rows = len(prices_df)\n",
    "print(f'Original Length: {num_rows}')\n",
    "train_df = prices_df[:np.round(num_rows/2).astype(int)]\n",
    "num_rows = len(train_df)\n",
    "print(f'Train Length: {num_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10806\n",
      "2467\n"
     ]
    }
   ],
   "source": [
    "# Let's identify stocks with no null values\n",
    "complete_stock_list = train_df.columns\n",
    "non_null_stocks = []\n",
    "for stock in complete_stock_list:\n",
    "    # get the count of nulls\n",
    "    null_count = train_df[stock].isnull().sum()\n",
    "    if null_count == 0:\n",
    "        non_null_stocks.append(stock)\n",
    "\n",
    "print(len(complete_stock_list))\n",
    "print(len(non_null_stocks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EQR']\n"
     ]
    }
   ],
   "source": [
    "# non_null_stocks is the list of usable stocks\n",
    "query = \"EQR\"\n",
    "\n",
    "matches = [s for s in non_null_stocks if query in s]\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Market_dict = {\n",
    "    'Technology': ['AAPL','MSFT','NVDA','ORCL','CSCO','IBM','ADBE','AMD','TXN','INTC'],\n",
    "    'Financial Services' : ['AXP','BLK','PGR','','','','','','',''],\n",
    "    'Consumer Cyclical': ['AMZN','HD','MCD','BKNG','LOW','TJX','SBUX','ORLY','',''],\n",
    "    'Healthcare' : ['LLY','UNH','JNJ','MRK','ABT','AMGN','CVS','','',''],\n",
    "    'Communication Services': ['TTWO','OMC','EA','','','','','','',''],\n",
    "    'Industrials' : ['CAT','UNP','HON','BA','DE','ETN','UPS','WM','MMM','CTAS'],\n",
    "    'Consumer Defensive' : ['WMT','COST','PG','KO','PEP','MO','CL','TGT','MNST','KR'],\n",
    "    'Energy': ['XOM','COP','CVX','EPD','EOG','WMB','SLB','OKE','VLO','EQT'],\n",
    "    'Basic Materials' : ['SHW','APD','SCCO','ECL','NEM','VMC','MLM','NUE','PPG','STLD'],\n",
    "    'Real Estate' : ['PLD','AVB','CSGP','IRM','EQR','','','','',''],\n",
    "    'Utilities': ['','','','','','','','','','']\n",
    "}\n",
    "# This is just some of the stocks that are available... maybe this could be better solved later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr_matrix(DataFrame):\n",
    "    return DataFrame.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster(DataFrame, num_clusters):\n",
    "    X = get_corr_matrix(DataFrame)\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=2, n_init=20).fit(X)\n",
    "    cluster_dict = {}\n",
    "    # Iterate over the indices of cluster_list\n",
    "    for i in range(len(kmeans.labels_)):\n",
    "        cluster_number = kmeans.labels_[i]\n",
    "        stock_name = DataFrame.columns[i]\n",
    "        # Check if cluster_number is already a key in the dictionary\n",
    "        if cluster_number in cluster_dict:\n",
    "            cluster_dict[cluster_number].append(stock_name)\n",
    "        else:\n",
    "            cluster_dict[cluster_number] = [stock_name]\n",
    "    return cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_clustering(DataFrame, months_to_run):\n",
    "    # Set up the log\n",
    "    cluster_log = {}\n",
    "    # Get the list of timestamps (assuming the index is a list of Timestamps)\n",
    "    index = DataFrame.index.tolist()\n",
    "    # Start from the first timestamp\n",
    "    first_day = index[0]\n",
    "    for _ in range(months_to_run):\n",
    "        # Calculate the last day of the month based on the current first day\n",
    "        last_day_of_month = pd.Timestamp(first_day.year, first_day.month, 1) + pd.offsets.MonthEnd(0) \n",
    "        # Cluster data for the month\n",
    "        cluster_entry = cluster(DataFrame[first_day:last_day_of_month], 2)\n",
    "        cluster_log[last_day_of_month] = cluster_entry \n",
    "        # Find the index position of the last day of the month in the list of timestamps\n",
    "        last_day_position = None\n",
    "        current_last_day = last_day_of_month \n",
    "        # Keep searching until we find a valid index position for the last day of the month\n",
    "        while last_day_position is None:\n",
    "            try:\n",
    "                last_day_position = next(\n",
    "                    i for i, t in enumerate(index) if t.date() == current_last_day.date()\n",
    "                )\n",
    "            except StopIteration:\n",
    "                # Backtrack by one day and try again if not found\n",
    "                current_last_day -= pd.Timedelta(days=1)\n",
    "                # If backtracking goes too far, raise an error\n",
    "                if current_last_day < first_day:\n",
    "                    raise ValueError(\n",
    "                        f\"Could not find a suitable last day for the month starting at {first_day}. \"\n",
    "                        \"Backtracking exceeded the first day.\"\n",
    "                    )\n",
    "        # Move to the next day after the last day of this month\n",
    "        next_day = current_last_day + pd.Timedelta(days=1)\n",
    "        # Keep moving to the next day until a valid first day is found\n",
    "        while next_day not in index:\n",
    "            next_day += pd.Timedelta(days=1)\n",
    "        # Set the first day for the next month\n",
    "        first_day = next_day\n",
    "    return cluster_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weekly_clustering(DataFrame, weeks_to_run):\n",
    "    # Set up the log\n",
    "    cluster_log = {}\n",
    "    # Get the list of timestamps (assuming the index is a list of Timestamps)\n",
    "    index = DataFrame.index.tolist()\n",
    "    # Start from the first timestamp\n",
    "    first_day = index[0]\n",
    "    index_position = 0  # Keeps track of the current position in the list of timestamps\n",
    "    for _ in range(weeks_to_run):\n",
    "        # Calculate the last day of the week based on the current first day\n",
    "        last_day_of_week = first_day + pd.Timedelta(days=(6 - first_day.weekday()))  # Last day of the week (Sunday)\n",
    "        # Ensure last_day_of_week is within the available data range\n",
    "        if last_day_of_week > index[-1]:\n",
    "            last_day_of_week = index[-1]\n",
    "        # Cluster data for this week\n",
    "        cluster_entry = cluster(DataFrame[first_day:last_day_of_week], 2)\n",
    "        cluster_log[last_day_of_week] = cluster_entry\n",
    "        # Move to the next day after the last day of this week\n",
    "        next_day = last_day_of_week + pd.Timedelta(days=1)\n",
    "        # Keep moving to the next day until a valid index is found\n",
    "        while next_day not in index:\n",
    "            next_day += pd.Timedelta(days=1)\n",
    "        # Set the first day of the next week\n",
    "        first_day = next_day\n",
    "    return cluster_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_log_to_df(cluster_dict):\n",
    "    # Create a list to hold DataFrame rows\n",
    "    rows = []\n",
    "    # Populate the rows with timestamp, stock, and cluster\n",
    "    for timestamp, clusters in cluster_dict.items():\n",
    "        for cluster_id, stocks in clusters.items():\n",
    "            for stock in stocks:\n",
    "                rows.append({'timestamp': timestamp, 'stock': stock, 'cluster': cluster_id})\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame(rows)\n",
    "    # Pivot the DataFrame to get the desired format\n",
    "    result = df.pivot(index='timestamp', columns='stock', values='cluster')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_viz(dataframe):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_to_run = ['AAPL', 'MSFT', 'NVDA', 'ORCL','XOM', 'COP', 'CVX', 'EPD']\n",
    "monthly_log = monthly_clustering(train_df[stocks_to_run], 5)\n",
    "results_df = convert_log_to_df(monthly_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>stock</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>COP</th>\n",
       "      <th>CVX</th>\n",
       "      <th>EPD</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>ORCL</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-31</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-29</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-03-31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-30</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-31</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "stock       AAPL  COP  CVX  EPD  MSFT  NVDA  ORCL  XOM\n",
       "timestamp                                             \n",
       "2000-01-31     1    0    0    1     0     0     0    0\n",
       "2000-02-29     0    1    1    1     1     0     0    1\n",
       "2000-03-31     0    0    0    1     0     1     0    1\n",
       "2000-04-30     0    1    0    1     0     0     0    0\n",
       "2000-05-31     0    1    1    1     0     1     0    1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
