{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports, Setup, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from numpy import linalg as LA\n",
    "from sklearn.cluster import KMeans\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from itertools import combinations\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "import random\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATW</th>\n",
       "      <th>A</th>\n",
       "      <th>AA</th>\n",
       "      <th>AAAB</th>\n",
       "      <th>AABC</th>\n",
       "      <th>AAC1</th>\n",
       "      <th>AACC</th>\n",
       "      <th>AACE</th>\n",
       "      <th>AACH</th>\n",
       "      <th>AADI</th>\n",
       "      <th>...</th>\n",
       "      <th>ZVIA</th>\n",
       "      <th>ZVOI</th>\n",
       "      <th>ZVRA</th>\n",
       "      <th>ZVUE</th>\n",
       "      <th>ZVXI</th>\n",
       "      <th>ZY</th>\n",
       "      <th>ZYME</th>\n",
       "      <th>ZYNE</th>\n",
       "      <th>ZYXI</th>\n",
       "      <th>ZZ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>0.265785</td>\n",
       "      <td>14.803789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.074688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>0.355094</td>\n",
       "      <td>13.938379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>0.597657</td>\n",
       "      <td>15.593232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082724</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>0.377474</td>\n",
       "      <td>6.688876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>0.698268</td>\n",
       "      <td>8.061751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.061952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 10806 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ATW          A  AA      AAAB      AABC      AAC1  AACC  \\\n",
       "date                                                                      \n",
       "2000-01-03  0.265785  14.803789 NaN  0.002968  0.000000  0.055383   NaN   \n",
       "2000-01-04  0.355094  13.938379 NaN  0.001050  0.000000  0.093997   NaN   \n",
       "2000-01-05  0.597657  15.593232 NaN  0.002262  0.000000  0.082724   NaN   \n",
       "2000-01-06  0.377474   6.688876 NaN  0.003307  0.000000  0.071145   NaN   \n",
       "2000-01-07  0.698268   8.061751 NaN  0.001843  0.000426  0.061952   NaN   \n",
       "\n",
       "                AACE  AACH  AADI  ...  ZVIA  ZVOI  ZVRA  ZVUE      ZVXI  ZY  \\\n",
       "date                              ...                                         \n",
       "2000-01-03  0.074688   NaN   NaN  ...   NaN   NaN   NaN   NaN  0.010821 NaN   \n",
       "2000-01-04  0.036322   NaN   NaN  ...   NaN   NaN   NaN   NaN  0.001050 NaN   \n",
       "2000-01-05  0.042248   NaN   NaN  ...   NaN   NaN   NaN   NaN  0.002725 NaN   \n",
       "2000-01-06  0.022496   NaN   NaN  ...   NaN   NaN   NaN   NaN  0.006309 NaN   \n",
       "2000-01-07  0.005193   NaN   NaN  ...   NaN   NaN   NaN   NaN  0.033459 NaN   \n",
       "\n",
       "            ZYME  ZYNE  ZYXI  ZZ  \n",
       "date                              \n",
       "2000-01-03   NaN   NaN   NaN NaN  \n",
       "2000-01-04   NaN   NaN   NaN NaN  \n",
       "2000-01-05   NaN   NaN   NaN NaN  \n",
       "2000-01-06   NaN   NaN   NaN NaN  \n",
       "2000-01-07   NaN   NaN   NaN NaN  \n",
       "\n",
       "[5 rows x 10806 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap_path = '/Users/tuckeringlefield/Desktop/Data_Science/Math_4920/Stocks_Data/cap_data_from_shardar.csv'\n",
    "price_path = \"/Users/tuckeringlefield/Desktop/Data_Science/Math_4920/Stocks_Data/price_data_from_shardar.csv\"\n",
    "\n",
    "# Reading Data:\n",
    "prices_df = pd.read_csv(price_path, index_col='date')\n",
    "caps_df = pd.read_csv(cap_path, index_col='date')\n",
    "\n",
    "# Drop troubled stock...\n",
    "prices_df.drop([\"MGI\", \"MDLZ\", \"DWA\", \"ICE\"], axis=1, inplace=True)\n",
    "caps_df.drop([\"MGI\", \"MDLZ\", \"DWA\", \"ICE\"], axis=1, inplace=True)\n",
    "\n",
    "prices_df.head()\n",
    "caps_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "prices_df.index = pd.to_datetime(prices_df.index)\n",
    "\n",
    "# Get the initial start and end date\n",
    "start_date = prices_df.index[0]\n",
    "end_date = prices_df.index[-1]\n",
    "\n",
    "# Download additional data:\n",
    "spy_data = yf.download('SPY', start=start_date, end=end_date, interval='1d')\n",
    "spy_data = pd.DataFrame(spy_data[\"Adj Close\"])\n",
    "spy_data.rename({\"Adj Close\": 'SPY'}, inplace=True, axis=1)\n",
    "\n",
    "# Set up dataframes:\n",
    "prices_with_market = prices_df.merge(spy_data, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Length: 5787\n",
      "Train Length: 2894\n"
     ]
    }
   ],
   "source": [
    "# Pulling rougly the first half of data\n",
    "num_rows = len(prices_df)\n",
    "print(f'Original Length: {num_rows}')\n",
    "train_df = prices_df[:np.round(num_rows/2).astype(int)]\n",
    "num_rows = len(train_df)\n",
    "print(f'Train Length: {num_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10806\n",
      "2467\n"
     ]
    }
   ],
   "source": [
    "# Let's identify stocks with no null values\n",
    "complete_stock_list = train_df.columns\n",
    "non_null_stocks = []\n",
    "for stock in complete_stock_list:\n",
    "    # get the count of nulls\n",
    "    null_count = train_df[stock].isnull().sum()\n",
    "    if null_count == 0:\n",
    "        non_null_stocks.append(stock)\n",
    "\n",
    "print(len(complete_stock_list))\n",
    "print(len(non_null_stocks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EQR']\n"
     ]
    }
   ],
   "source": [
    "# non_null_stocks is the list of usable stocks\n",
    "query = \"EQR\"\n",
    "\n",
    "matches = [s for s in non_null_stocks if query in s]\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "Market_dict = {\n",
    "    'Technology': ['AAPL','MSFT','NVDA','ORCL','CSCO','IBM','ADBE','AMD','TXN','INTC'],\n",
    "    'Financial Services' : ['AXP','BLK','PGR','','','','','','',''],\n",
    "    'Consumer Cyclical': ['AMZN','HD','MCD','BKNG','LOW','TJX','SBUX','ORLY','',''],\n",
    "    'Healthcare' : ['LLY','UNH','JNJ','MRK','ABT','AMGN','CVS','','',''],\n",
    "    'Communication Services': ['TTWO','OMC','EA','','','','','','',''],\n",
    "    'Industrials' : ['CAT','UNP','HON','BA','DE','ETN','UPS','WM','MMM','CTAS'],\n",
    "    'Consumer Defensive' : ['WMT','COST','PG','KO','PEP','MO','CL','TGT','MNST','KR'],\n",
    "    'Energy': ['XOM','COP','CVX','EPD','EOG','WMB','SLB','OKE','VLO','EQT'],\n",
    "    'Basic Materials' : ['SHW','APD','SCCO','ECL','NEM','VMC','MLM','NUE','PPG','STLD'],\n",
    "    'Real Estate' : ['PLD','AVB','CSGP','IRM','EQR','','','','',''],\n",
    "    'Utilities': ['','','','','','','','','','']\n",
    "}\n",
    "# This is just some of the stocks that are available... maybe this could be better solved later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr_matrix(DataFrame):\n",
    "    return DataFrame.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_mean_cluster(DataFrame, num_clusters):\n",
    "    X = get_corr_matrix(DataFrame)\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=2, n_init=20).fit(X)\n",
    "    cluster_dict = {}\n",
    "    # Iterate over the indices of cluster_list\n",
    "    for i in range(len(kmeans.labels_)):\n",
    "        cluster_number = kmeans.labels_[i]\n",
    "        stock_name = DataFrame.columns[i]\n",
    "        # Check if cluster_number is already a key in the dictionary\n",
    "        if cluster_number in cluster_dict:\n",
    "            cluster_dict[cluster_number].append(stock_name)\n",
    "        else:\n",
    "            cluster_dict[cluster_number] = [stock_name]\n",
    "    return cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_cluster(df, num_clusters):\n",
    "    A = abs(df.corr().values)\n",
    "    D = np.diag(A.sum(axis=1))\n",
    "    L = D - A\n",
    "    eigenvalues, eigenvectors = LA.eig(L)\n",
    "    X = eigenvectors[:,:num_clusters]\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=2, n_init=20).fit(X)\n",
    "    cluster_dict = {}\n",
    "    # Iterate over the indices of cluster_list\n",
    "    for i in range(len(kmeans.labels_)):\n",
    "        cluster_number = kmeans.labels_[i]\n",
    "        stock_name = df.columns[i]\n",
    "        # Check if cluster_number is already a key in the dictionary\n",
    "        if cluster_number in cluster_dict:\n",
    "            cluster_dict[cluster_number].append(stock_name)\n",
    "        else:\n",
    "            cluster_dict[cluster_number] = [stock_name]\n",
    "    return cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_clustering(DataFrame, months_to_run, cluster_method):\n",
    "    # Set up the log\n",
    "    cluster_log = {}\n",
    "    # Get the list of timestamps (assuming the index is a list of Timestamps)\n",
    "    index = DataFrame.index.tolist()\n",
    "    # Start from the first timestamp\n",
    "    first_day = index[0]\n",
    "    for _ in range(months_to_run):\n",
    "        # Calculate the last day of the month based on the current first day\n",
    "        last_day_of_month = pd.Timestamp(first_day.year, first_day.month, 1) + pd.offsets.MonthEnd(0) \n",
    "        # Cluster data for the month\n",
    "        if cluster_method == 'KMean':\n",
    "            cluster_entry = K_mean_cluster(DataFrame[first_day:last_day_of_month], 2)\n",
    "        else:\n",
    "            cluster_entry = spectral_cluster(DataFrame[first_day:last_day_of_month], 2)\n",
    "        print(cluster_entry)\n",
    "        cluster_log[last_day_of_month] = cluster_entry \n",
    "        # Find the index position of the last day of the month in the list of timestamps\n",
    "        last_day_position = None\n",
    "        current_last_day = last_day_of_month \n",
    "        # Keep searching until we find a valid index position for the last day of the month\n",
    "        while last_day_position is None:\n",
    "            try:\n",
    "                last_day_position = next(\n",
    "                    i for i, t in enumerate(index) if t.date() == current_last_day.date()\n",
    "                )\n",
    "            except StopIteration:\n",
    "                # Backtrack by one day and try again if not found\n",
    "                current_last_day -= pd.Timedelta(days=1)\n",
    "                # If backtracking goes too far, raise an error\n",
    "                if current_last_day < first_day:\n",
    "                    raise ValueError(\n",
    "                        f\"Could not find a suitable last day for the month starting at {first_day}. \"\n",
    "                        \"Backtracking exceeded the first day.\"\n",
    "                    )\n",
    "        # Move to the next day after the last day of this month\n",
    "        next_day = current_last_day + pd.Timedelta(days=1)\n",
    "        # Keep moving to the next day until a valid first day is found\n",
    "        while next_day not in index:\n",
    "            next_day += pd.Timedelta(days=1)\n",
    "        # Set the first day for the next month\n",
    "        first_day = next_day\n",
    "    return cluster_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_log_to_df(cluster_dict):\n",
    "    # Create a list to hold DataFrame rows\n",
    "    rows = []\n",
    "    # Populate the rows with timestamp, stock, and cluster\n",
    "    for timestamp, clusters in cluster_dict.items():\n",
    "        for cluster_id, stocks in clusters.items():\n",
    "            for stock in stocks:\n",
    "                rows.append({'timestamp': timestamp, 'stock': stock, 'cluster': cluster_id})\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame(rows)\n",
    "    # Pivot the DataFrame to get the desired format\n",
    "    result = df.pivot(index='timestamp', columns='stock', values='cluster')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_viz(cluster_df, market_dict):\n",
    "    timestamps = cluster_df.index.tolist()\n",
    "    num_timestamps = len(timestamps)\n",
    "    # Create a figure with 2 rows and 2 columns per timestamp (one per cluster)\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=num_timestamps * 2, figsize=(num_timestamps * 4, 6))\n",
    "    # Loop over each timestamp and cluster\n",
    "    for t, timestamp in enumerate(timestamps):\n",
    "        row_data = cluster_df.loc[timestamp]  # Get the stock-cluster mapping for the timestamp\n",
    "        # --- Add timestamp suptitle centered above its two columns ---\n",
    "        fig.text(\n",
    "            x=(t * 2 + 1) / (num_timestamps * 2),  # Centered above the two cluster columns\n",
    "            y=1,  # Position above the plots\n",
    "            s=str(timestamp),\n",
    "            fontsize=14,\n",
    "            fontweight=\"bold\",\n",
    "            ha=\"center\"\n",
    "        )\n",
    "        for cluster in [0, 1]:\n",
    "            # Find stocks that belong to this cluster\n",
    "            stocks_in_cluster = row_data[row_data == cluster].index.tolist()\n",
    "            # --- First row: Bar Plot of Stock Count by Sector ---\n",
    "            sector_counts = {}\n",
    "            for sector, sector_stocks in market_dict.items():\n",
    "                valid_stocks = list(set(sector_stocks) & set(cluster_df.columns))\n",
    "                count = sum([1 for stock in valid_stocks if stock in stocks_in_cluster])\n",
    "                if count > 0:  # Only keep sectors that have at least one stock in the cluster\n",
    "                    sector_counts[sector] = count\n",
    "            ax_bar = axes[0, t * 2 + cluster]\n",
    "            if sector_counts:\n",
    "                sectors = list(sector_counts.keys())\n",
    "                values = list(sector_counts.values())  \n",
    "                ax_bar.bar(sectors, values)\n",
    "                ax_bar.tick_params(axis='x', rotation=45)\n",
    "            else:\n",
    "                ax_bar.set_xticks([])\n",
    "                ax_bar.set_yticks([])\n",
    "                ax_bar.text(0.5, 0.5, \"No sectors\", ha=\"center\", va=\"center\", fontsize=10)\n",
    "            ax_bar.set_title(f\"Cluster {cluster}\", fontsize=10)\n",
    "            # --- Second row: Text Plot Listing Stocks by Sector ---\n",
    "            text_str = \"\"\n",
    "            for sector, sector_stocks in market_dict.items():\n",
    "                valid_stocks = list(set(sector_stocks) & set(cluster_df.columns))\n",
    "                stocks_in_sector = [stock for stock in valid_stocks if stock in stocks_in_cluster]    \n",
    "                if stocks_in_sector:\n",
    "                    stock_list = \", \".join(stocks_in_sector)\n",
    "                    text_str += f\"{sector}:\\n{stock_list}\\n\\n\"\n",
    "            ax_text = axes[1, t * 2 + cluster]\n",
    "            ax_text.axis('off')\n",
    "            if text_str:\n",
    "                ax_text.text(0.5, 0.5, text_str, ha=\"center\", va=\"center\", wrap=True, fontsize=8)\n",
    "            else:\n",
    "                ax_text.text(0.5, 0.5, \"No sectors\", ha=\"center\", va=\"center\", wrap=True, fontsize=10)  \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should read off of dictionary structure\n",
    "def Calc_SectorCluster_metrics(results_dict, sector_dict):\n",
    "    data = []\n",
    "    for timestamp in list(results_dict.keys()):\n",
    "        # calculate the metrics for the two clusters\n",
    "        calcs = []\n",
    "        for cluster in list(results_dict[timestamp].keys()):\n",
    "            clusters_stocks = list(results_dict[timestamp][cluster])\n",
    "            # calculate the purity\n",
    "            count = Counter(clusters_stocks)\n",
    "            most_common_stock, most_common_count = count.most_common(1)[0]\n",
    "            total = len(clusters_stocks)\n",
    "            purity = (most_common_count/total)*100\n",
    "            calcs.append((f'Cluster{cluster}_Purity',purity))\n",
    "            # calculate the missclassification rate\n",
    "            missclassification_rate = (1-(most_common_count/total))*100\n",
    "            calcs.append((f'Cluster{cluster}_MR',missclassification_rate))\n",
    "            # calculate the entropy\n",
    "            entropy = -sum((freq / total) * math.log(freq / total) for freq in count.values())\n",
    "            calcs.append((f'Cluster{cluster}_Entropy',entropy))\n",
    "        new_row = {'timestamp': timestamp}\n",
    "        for i in calcs:\n",
    "            key = i[0]\n",
    "            val = i[1]\n",
    "            new_row[key] = val\n",
    "        data.append(new_row)\n",
    "    df = pd.DataFrame(data)\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_trading(DataFrame, months_to_run, cluster_method, num_clusters):\n",
    "    ### Setup\n",
    "    output_data = []\n",
    "    # Get the list of timestamps (assuming the index is a list of Timestamps)\n",
    "    index = DataFrame.index.tolist()\n",
    "    # Start from the first timestamp\n",
    "    first_day = index[0]   \n",
    "\n",
    "    ### Monthly Iteration\n",
    "    for _ in range(months_to_run):\n",
    "\n",
    "        ### Setup\n",
    "        new_row = {}\n",
    "        # Calculate the last day of the month based on the current first day\n",
    "        last_day_of_month = pd.Timestamp(first_day.year, first_day.month, 1) + pd.offsets.MonthEnd(0) \n",
    "        # Find the index position of the last day of the month in the list of timestamps\n",
    "        last_day_position = None\n",
    "        current_last_day = last_day_of_month \n",
    "        new_row['timestamp'] = current_last_day\n",
    "        # Keep searching until we find a valid index position for the last day of the month\n",
    "        while last_day_position is None:\n",
    "            try:\n",
    "                last_day_position = next(\n",
    "                    i for i, t in enumerate(index) if t.date() == current_last_day.date()\n",
    "                )\n",
    "            except StopIteration:\n",
    "                # Backtrack by one day and try again if not found\n",
    "                current_last_day -= pd.Timedelta(days=1)\n",
    "                # If backtracking goes too far, raise an error\n",
    "                if current_last_day < first_day:\n",
    "                    raise ValueError(\n",
    "                        f\"Could not find a suitable last day for the month starting at {first_day}. \"\n",
    "                        \"Backtracking exceeded the first day.\"\n",
    "                    )\n",
    "        # Move to the next day after the last day of this month\n",
    "        next_day = current_last_day + pd.Timedelta(days=1)\n",
    "        # Keep moving to the next day until a valid first day is found\n",
    "        while next_day not in index:\n",
    "            next_day += pd.Timedelta(days=1)\n",
    "\n",
    "        ### Clustering\n",
    "        if cluster_method == 'KMeans':\n",
    "            cluster_entry = K_mean_cluster(DataFrame[first_day:last_day_of_month], num_clusters)\n",
    "        else:\n",
    "            cluster_entry = spectral_cluster(DataFrame[first_day:last_day_of_month], num_clusters)\n",
    "        # assign the the cluster members appropriately\n",
    "        for cluster in list(cluster_entry.keys()):\n",
    "            new_row[f'Cluster_{cluster}_Members'] = cluster_entry[cluster]\n",
    "\n",
    "            ### Metric calculation\n",
    "            calcs = []\n",
    "            clusters_stocks = cluster_entry[cluster]\n",
    "            # calculate the purity\n",
    "            count = Counter(clusters_stocks)\n",
    "            most_common_stock, most_common_count = count.most_common(1)[0]\n",
    "            total = len(clusters_stocks)\n",
    "            purity = (most_common_count/total)*100\n",
    "            calcs.append((f'Cluster_{cluster}_Purity',purity))   \n",
    "            # calculate the missclassification rate\n",
    "            missclassification_rate = (1-(most_common_count/total))*100\n",
    "            calcs.append((f'Cluster_{cluster}_MR',missclassification_rate))\n",
    "            # calculate the entropy\n",
    "            prob = purity/100\n",
    "            if prob == 0 or prob == 1:\n",
    "                entropy = 0  # log2(0) is undefined, and entropy should be 0 for pure sets\n",
    "            else:\n",
    "                entropy = -1 * ((prob * np.log2(prob)) + ((1 - prob) * np.log2(1 - prob)))\n",
    "            calcs.append((f'Cluster_{cluster}_Entropy',entropy))\n",
    "            # assign the values appropriately\n",
    "            for i in calcs:\n",
    "                key = i[0]\n",
    "                val = i[1]\n",
    "                new_row[key] = val\n",
    "\n",
    "        ### Trading\n",
    "        \n",
    "        ### Cleanup\n",
    "        # Set the first day for the next month\n",
    "        first_day = next_day\n",
    "        # Append the month's row\n",
    "        output_data.append(new_row)\n",
    "    ### Output\n",
    "    df = pd.DataFrame(output_data)\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster_1_Members</th>\n",
       "      <th>Cluster_1_Purity</th>\n",
       "      <th>Cluster_1_MR</th>\n",
       "      <th>Cluster_1_Entropy</th>\n",
       "      <th>Cluster_0_Members</th>\n",
       "      <th>Cluster_0_Purity</th>\n",
       "      <th>Cluster_0_MR</th>\n",
       "      <th>Cluster_0_Entropy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-31</th>\n",
       "      <td>[AAPL, EPD]</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[MSFT, NVDA, ORCL, XOM, COP, CVX]</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>0.650022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-29</th>\n",
       "      <td>[MSFT, XOM, COP, CVX, EPD]</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.721928</td>\n",
       "      <td>[AAPL, NVDA, ORCL]</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>0.918296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-03-31</th>\n",
       "      <td>[NVDA, XOM, EPD]</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>0.918296</td>\n",
       "      <td>[AAPL, MSFT, ORCL, COP, CVX]</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.721928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-30</th>\n",
       "      <td>[COP, EPD]</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[AAPL, MSFT, NVDA, ORCL, XOM, CVX]</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>0.650022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-31</th>\n",
       "      <td>[NVDA, XOM, COP, CVX, EPD]</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.721928</td>\n",
       "      <td>[AAPL, MSFT, ORCL]</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>0.918296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Cluster_1_Members  Cluster_1_Purity  Cluster_1_MR  \\\n",
       "timestamp                                                                \n",
       "2000-01-31                 [AAPL, EPD]         50.000000     50.000000   \n",
       "2000-02-29  [MSFT, XOM, COP, CVX, EPD]         20.000000     80.000000   \n",
       "2000-03-31            [NVDA, XOM, EPD]         33.333333     66.666667   \n",
       "2000-04-30                  [COP, EPD]         50.000000     50.000000   \n",
       "2000-05-31  [NVDA, XOM, COP, CVX, EPD]         20.000000     80.000000   \n",
       "\n",
       "            Cluster_1_Entropy                   Cluster_0_Members  \\\n",
       "timestamp                                                           \n",
       "2000-01-31           1.000000   [MSFT, NVDA, ORCL, XOM, COP, CVX]   \n",
       "2000-02-29           0.721928                  [AAPL, NVDA, ORCL]   \n",
       "2000-03-31           0.918296        [AAPL, MSFT, ORCL, COP, CVX]   \n",
       "2000-04-30           1.000000  [AAPL, MSFT, NVDA, ORCL, XOM, CVX]   \n",
       "2000-05-31           0.721928                  [AAPL, MSFT, ORCL]   \n",
       "\n",
       "            Cluster_0_Purity  Cluster_0_MR  Cluster_0_Entropy  \n",
       "timestamp                                                      \n",
       "2000-01-31         16.666667     83.333333           0.650022  \n",
       "2000-02-29         33.333333     66.666667           0.918296  \n",
       "2000-03-31         20.000000     80.000000           0.721928  \n",
       "2000-04-30         16.666667     83.333333           0.650022  \n",
       "2000-05-31         33.333333     66.666667           0.918296  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks_to_run = ['AAPL', 'MSFT', 'NVDA', 'ORCL','XOM', 'COP', 'CVX', 'EPD']\n",
    "monthly_trading(train_df[stocks_to_run], 5, \"KMeans\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.50000000e+01, -8.91315789e-02],\n",
       "       [-8.91315789e-02,  2.67561342e-02]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_df = train_df['NVDA']['2000-03-31':'2000-04-30']\n",
    "covariance = np.cov(range(len(copy_df)), copy_df.values)\n",
    "covariance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
