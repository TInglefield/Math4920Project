{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports, Setup, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from numpy import linalg as LA\n",
    "from sklearn.cluster import KMeans\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from itertools import combinations\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "import random\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_path = '/Users/tuckeringlefield/Desktop/Data_Science/Math_4920/Stocks_Data/cap_data_from_shardar.csv'\n",
    "price_path = \"/Users/tuckeringlefield/Desktop/Data_Science/Math_4920/Stocks_Data/price_data_from_shardar.csv\"\n",
    "\n",
    "# Reading Data:\n",
    "prices_df = pd.read_csv(price_path, index_col='date')\n",
    "caps_df = pd.read_csv(cap_path, index_col='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Length: 5787\n",
      "Train Length: 2894\n"
     ]
    }
   ],
   "source": [
    "# Pulling rougly the first half of data\n",
    "num_rows = len(prices_df)\n",
    "print(f'Original Length: {num_rows}')\n",
    "train_df = prices_df[:np.round(num_rows/2).astype(int)]\n",
    "num_rows = len(train_df)\n",
    "print(f'Train Length: {num_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10810\n",
      "2467\n"
     ]
    }
   ],
   "source": [
    "# Let's identify stocks with no null values\n",
    "complete_stock_list = train_df.columns\n",
    "non_null_stocks = []\n",
    "for stock in complete_stock_list:\n",
    "    # get the count of nulls\n",
    "    null_count = train_df[stock].isnull().sum()\n",
    "    if null_count == 0:\n",
    "        non_null_stocks.append(stock)\n",
    "\n",
    "print(len(complete_stock_list))\n",
    "print(len(non_null_stocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[non_null_stocks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Market_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/tuckeringlefield/Desktop/Data_Science/Math_4920/Stocks_Data/Nasdaq_sectors.csv'\n",
    "nasdaq_sectors = pd.read_csv(file_path)\n",
    "cols_to_keep = ['Symbol', 'Sector']\n",
    "nasdaq_sectors = nasdaq_sectors[cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Sector in nasdaq_sectors['Sector'].unique().tolist():\n",
    "    if pd.notna(Sector):\n",
    "        Market_dict[Sector] = []\n",
    "        temp_df = nasdaq_sectors[nasdaq_sectors['Sector']==Sector]\n",
    "        for stk in temp_df['Symbol'].unique().tolist():\n",
    "            if stk in non_null_stocks:\n",
    "                Market_dict[Sector].append(stk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Industrials\n",
      "202\n",
      "Finance\n",
      "186\n",
      "Real Estate\n",
      "42\n",
      "Health Care\n",
      "124\n",
      "Consumer Discretionary\n",
      "275\n",
      "Technology\n",
      "139\n",
      "Basic Materials\n",
      "13\n",
      "Consumer Staples\n",
      "40\n",
      "Energy\n",
      "47\n",
      "Miscellaneous\n",
      "9\n",
      "Utilities\n",
      "43\n",
      "Telecommunications\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "for Sector in list(Market_dict.keys()):\n",
    "    print(Sector)\n",
    "    print(len(Market_dict[Sector]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_market_dict = Market_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cap_market_dict = {}\n",
    "for Sector in list(Market_dict.keys()):\n",
    "    Sector_stocks = Market_dict[Sector]\n",
    "    Sector_df = caps_df[Sector_stocks]\n",
    "    top_10_stocks = list(Sector_df.mean().nlargest(10).index)\n",
    "    top_cap_market_dict[Sector] = top_10_stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr_matrix(DataFrame):\n",
    "    return DataFrame.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_mean_cluster_not_given_corr_matrix(DataFrame, num_clusters):\n",
    "    X = get_corr_matrix(DataFrame)\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=2, n_init=20).fit(X)\n",
    "    cluster_dict = {}\n",
    "    # Iterate over the indices of cluster_list\n",
    "    for i in range(len(kmeans.labels_)):\n",
    "        cluster_number = kmeans.labels_[i]\n",
    "        stock_name = DataFrame.columns[i]\n",
    "        # Check if cluster_number is already a key in the dictionary\n",
    "        if cluster_number in cluster_dict:\n",
    "            cluster_dict[cluster_number].append(stock_name)\n",
    "        else:\n",
    "            cluster_dict[cluster_number] = [stock_name]\n",
    "    return cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_cluster_not_given_corr_matrix(df, num_clusters):\n",
    "    A = abs(df.corr().values)\n",
    "    D = np.diag(A.sum(axis=1))\n",
    "    L = D - A\n",
    "    eigenvalues, eigenvectors = LA.eig(L)\n",
    "    X = eigenvectors[:,:num_clusters]\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=2, n_init=20).fit(X)\n",
    "    cluster_dict = {}\n",
    "    # Iterate over the indices of cluster_list\n",
    "    for i in range(len(kmeans.labels_)):\n",
    "        cluster_number = kmeans.labels_[i]\n",
    "        stock_name = df.columns[i]\n",
    "        # Check if cluster_number is already a key in the dictionary\n",
    "        if cluster_number in cluster_dict:\n",
    "            cluster_dict[cluster_number].append(stock_name)\n",
    "        else:\n",
    "            cluster_dict[cluster_number] = [stock_name]\n",
    "    return cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_mean_cluster_given_corr_matrix(DataFrame, num_clusters):\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=2, n_init=20).fit(DataFrame)\n",
    "    cluster_dict = {}\n",
    "    # Iterate over the indices of cluster_list\n",
    "    for i in range(len(kmeans.labels_)):\n",
    "        cluster_number = kmeans.labels_[i]\n",
    "        stock_name = DataFrame.columns[i]\n",
    "        # Check if cluster_number is already a key in the dictionary\n",
    "        if cluster_number in cluster_dict:\n",
    "            cluster_dict[cluster_number].append(stock_name)\n",
    "        else:\n",
    "            cluster_dict[cluster_number] = [stock_name]\n",
    "    return cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_cluster_given_corr_matrix(df, num_clusters):\n",
    "    A = abs(df.values)\n",
    "    D = np.diag(A.sum(axis=1))\n",
    "    L = D - A\n",
    "    eigenvalues, eigenvectors = LA.eig(L)\n",
    "    X = eigenvectors[:,:num_clusters]\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=2, n_init=20).fit(X)\n",
    "    cluster_dict = {}\n",
    "    # Iterate over the indices of cluster_list\n",
    "    for i in range(len(kmeans.labels_)):\n",
    "        cluster_number = kmeans.labels_[i]\n",
    "        stock_name = df.columns[i]\n",
    "        # Check if cluster_number is already a key in the dictionary\n",
    "        if cluster_number in cluster_dict:\n",
    "            cluster_dict[cluster_number].append(stock_name)\n",
    "        else:\n",
    "            cluster_dict[cluster_number] = [stock_name]\n",
    "    return cluster_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual with no clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomized with no clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual with clustering, beta for direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomized with clustering, beta for direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomized with Clustering, cap filtering, beta for direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_avg_profit(trading_dict):\n",
    "    all_profits = []\n",
    "    for stock in list(trading_dict.keys()):\n",
    "        profits = trading_dict[stock]['Profit']\n",
    "        for profit in profits:\n",
    "            all_profits.append(profit)\n",
    "    return (sum(all_profits)/len(all_profits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cum_sum(trading_dict):\n",
    "    all_profits = []\n",
    "    for stock in list(trading_dict.keys()):\n",
    "        profits = trading_dict[stock]['Profit']\n",
    "        for profit in profits:\n",
    "            all_profits.append(profit)\n",
    "    all_profits = np.array(all_profits)\n",
    "    return np.cumsum(all_profits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_trading_profit_df(trading_dict):\n",
    "    # Collect all timestamps and sort them\n",
    "    all_timestamps = sorted(set(ts for stock in trading_dict for ts in trading_dict[stock]['Close_date']))\n",
    "    \n",
    "    stock_profits = {'Time': all_timestamps}\n",
    "    \n",
    "    for stock, data in trading_dict.items():\n",
    "        stock_profits[stock] = []\n",
    "        trade_times = data['Close_date']\n",
    "        profits = data['Profit']\n",
    "        \n",
    "        cumulative_profit = 0\n",
    "        trade_index = 0\n",
    "        \n",
    "        for timestamp in all_timestamps:\n",
    "            if trade_index < len(trade_times) and trade_times[trade_index] == timestamp:\n",
    "                cumulative_profit += profits[trade_index]\n",
    "                trade_index += 1\n",
    "            \n",
    "            stock_profits[stock].append(cumulative_profit)\n",
    "    \n",
    "    return pd.DataFrame(stock_profits).set_index('Time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_trading_results(trading_results):\n",
    "    for stock, results in trading_results.items():\n",
    "        num_long = sum(1 for trade in results['Trade_type'] if trade == \"Long\")\n",
    "        num_short = len(results['Trade_type']) - num_long\n",
    "        \n",
    "        long_profit = [profit for trade, profit in zip(results['Trade_type'], results['Profit']) if trade == \"Long\"]\n",
    "        short_profit = [profit for trade, profit in zip(results['Trade_type'], results['Profit']) if trade == \"Short\"]\n",
    "        overall_profit = results['Profit']\n",
    "        \n",
    "        def calculate_positive_proportion(profits):\n",
    "            return sum(1 for p in profits if p > 0) / len(profits) if profits else None\n",
    "        \n",
    "        overall_proportion_pos = calculate_positive_proportion(overall_profit)\n",
    "        long_proportion_pos = calculate_positive_proportion(long_profit)\n",
    "        short_proportion_pos = calculate_positive_proportion(short_profit)\n",
    "        \n",
    "        print(stock)\n",
    "        print(f'Num Long: {num_long}', f'{long_proportion_pos:.2%} positive profit' if long_proportion_pos is not None else '')\n",
    "        print(f'Num Short: {num_short}', f'{short_proportion_pos:.2%} positive profit' if short_proportion_pos is not None else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cum_sum_plot_single(trading_results):\n",
    "    # Get all the possible timestamps\n",
    "    all_timestamps = sorted(set(ts for stock in trading_results for ts in trading_results[stock]['Close_date']))\n",
    "    \n",
    "    temp_data = {\n",
    "        'Time': all_timestamps,\n",
    "        'Cumulative_Sum': []\n",
    "    }\n",
    "    \n",
    "    cum_sum = 0\n",
    "    for timestamp in all_timestamps:\n",
    "        # Find profits for this timestamp\n",
    "        profits = []\n",
    "        for stock in trading_results:\n",
    "            for index_pos, ts in enumerate(trading_results[stock]['Close_date']):\n",
    "                if ts == timestamp:\n",
    "                    profits.append(trading_results[stock]['Profit'][index_pos])\n",
    "\n",
    "        # Ensure cumulative sum is increasing correctly\n",
    "        cum_sum += np.sum(profits)\n",
    "        temp_data['Cumulative_Sum'].append(cum_sum)\n",
    "    \n",
    "    return pd.DataFrame(temp_data).set_index('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cum_sum_plot_multiple(*trading_results):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i, results in enumerate(trading_results):\n",
    "        all_timestamps = sorted(set(ts for stock in results for ts in results[stock]['Close_date']))    \n",
    "        temp_data = {\n",
    "            'Time': all_timestamps,\n",
    "            'Cumulative_Sum': []\n",
    "        }\n",
    "        cum_sum = 0\n",
    "        for timestamp in all_timestamps:\n",
    "            profits = []\n",
    "            for stock in results:\n",
    "                for index_pos, ts in enumerate(results[stock]['Close_date']):\n",
    "                    if ts == timestamp:\n",
    "                        profits.append(results[stock]['Profit'][index_pos])\n",
    "            \n",
    "            cum_sum += np.sum(profits)\n",
    "            temp_data['Cumulative_Sum'].append(cum_sum)\n",
    "\n",
    "        df = pd.DataFrame(temp_data).set_index('Time')\n",
    "        # Plot each dataset with a unique label\n",
    "        plt.plot(df.index, df['Cumulative_Sum'], label=f'Num Sectors: {i+2}')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Cumulative Sum')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
