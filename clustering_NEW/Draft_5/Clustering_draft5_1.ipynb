{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from numpy import linalg as LA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from itertools import combinations\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "import random\n",
    "import matplotlib.gridspec as gridspec\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.collections as mcollections\n",
    "from scipy.cluster.hierarchy import dendrogram, cut_tree\n",
    "from ISLP.cluster import compute_linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_path = '/Users/tuckeringlefield/Desktop/Data_Science/Math_4920/Stocks_Data/cap_data_from_shardar.csv'\n",
    "price_path = \"/Users/tuckeringlefield/Desktop/Data_Science/Math_4920/Stocks_Data/price_data_from_shardar.csv\"\n",
    "\n",
    "# Reading Data:\n",
    "prices_df = pd.read_csv(price_path, index_col='date')\n",
    "prices_df.index = pd.to_datetime(prices_df.index)\n",
    "caps_df = pd.read_csv(cap_path, index_col='date')\n",
    "caps_df.index = pd.to_datetime(caps_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Length: 5787\n",
      "Train Length: 2894\n"
     ]
    }
   ],
   "source": [
    "# Pulling rougly the first half of data\n",
    "num_rows = len(prices_df)\n",
    "print(f'Original Length: {num_rows}')\n",
    "train_df = prices_df[:np.round(num_rows/2).astype(int)]\n",
    "caps_df = caps_df[:np.round(num_rows/2).astype(int)]\n",
    "num_rows = len(train_df)\n",
    "print(f'Train Length: {num_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10810\n",
      "2467\n"
     ]
    }
   ],
   "source": [
    "# Let's identify stocks with no null values\n",
    "complete_stock_list = train_df.columns\n",
    "non_null_stocks = []\n",
    "for stock in complete_stock_list:\n",
    "    # get the count of nulls\n",
    "    null_count = train_df[stock].isnull().sum()\n",
    "    if null_count == 0:\n",
    "        non_null_stocks.append(stock)\n",
    "\n",
    "print(len(complete_stock_list))\n",
    "print(len(non_null_stocks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Market_dict = {}\n",
    "file_path = '/Users/tuckeringlefield/Desktop/Data_Science/Math_4920/Stocks_Data/Nasdaq_sectors.csv'\n",
    "nasdaq_sectors = pd.read_csv(file_path)\n",
    "cols_to_keep = ['Symbol', 'Sector']\n",
    "nasdaq_sectors = nasdaq_sectors[cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Sector in nasdaq_sectors['Sector'].unique().tolist():\n",
    "    if pd.notna(Sector):\n",
    "        Market_dict[Sector] = []\n",
    "        temp_df = nasdaq_sectors[nasdaq_sectors['Sector']==Sector]\n",
    "        for stk in temp_df['Symbol'].unique().tolist():\n",
    "            if stk in complete_stock_list:\n",
    "                Market_dict[Sector].append(stk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Industrials\n",
      "343\n",
      "Finance\n",
      "430\n",
      "Real Estate\n",
      "101\n",
      "Health Care\n",
      "679\n",
      "Consumer Discretionary\n",
      "630\n",
      "Technology\n",
      "414\n",
      "Basic Materials\n",
      "19\n",
      "Consumer Staples\n",
      "75\n",
      "Energy\n",
      "100\n",
      "Miscellaneous\n",
      "24\n",
      "Utilities\n",
      "73\n",
      "Telecommunications\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "for Sector in list(Market_dict.keys()):\n",
    "    print(Sector)\n",
    "    print(len(Market_dict[Sector]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_market_dict = Market_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr_matrix(DataFrame):\n",
    "    #print()\n",
    "    return DataFrame.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_mean_clustering(DataFrame, num_clusters, n_init):\n",
    "    if (DataFrame.isnull().values.any()):\n",
    "        print('Warning: Null/NaN values found in clustering data')\n",
    "    X = get_corr_matrix(DataFrame)\n",
    "    if X.isnull().values.any():\n",
    "        print('Warning: Null/NaN values found in correlation data')\n",
    "    #X = ((1-X)/2.)**.5 #distance matrix\n",
    "    kmeans = KMeans(n_clusters=num_clusters, n_init=n_init).fit(X)\n",
    "    cluster_dict = {}\n",
    "    # Iterate over the indices of cluster_list\n",
    "    for i in range(len(kmeans.labels_)):\n",
    "        cluster_number = kmeans.labels_[i]\n",
    "        stock_name = DataFrame.columns[i]\n",
    "        # Check if cluster_number is already a key in the dictionary\n",
    "        if cluster_number in cluster_dict:\n",
    "            cluster_dict[cluster_number].append(stock_name)\n",
    "        else:\n",
    "            cluster_dict[cluster_number] = [stock_name] \n",
    "    return cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_clustering(df, num_clusters):\n",
    "    A = abs(df.corr().values)\n",
    "    #A = df.corr().values\n",
    "    D = np.diag(A.sum(axis=1))\n",
    "    L = D - A\n",
    "    eigenvalues, eigenvectors = LA.eig(L)\n",
    "    X = eigenvectors[:,:num_clusters]\n",
    "    kmeans = KMeans(n_clusters=num_clusters, n_init=20).fit(X)\n",
    "    cluster_dict = {}\n",
    "    # Iterate over the indices of cluster_list\n",
    "    for i in range(len(kmeans.labels_)):\n",
    "        cluster_number = kmeans.labels_[i]\n",
    "        stock_name = df.columns[i]\n",
    "        # Check if cluster_number is already a key in the dictionary\n",
    "        if cluster_number in cluster_dict:\n",
    "            cluster_dict[cluster_number].append(stock_name)\n",
    "        else:\n",
    "            cluster_dict[cluster_number] = [stock_name]\n",
    "    return cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hierarchical_clustering(df, num_clusters):\n",
    "    X = get_corr_matrix(df)\n",
    "    X = ((1-X)/2.)**.5 #distance matrix\n",
    "    HC_clustering = AgglomerativeClustering(n_clusters=num_clusters, linkage='average')\n",
    "    labels = HC_clustering.fit(X).labels_\n",
    "    stocks = X.columns.tolist()\n",
    "    cluster_dict = {}\n",
    "    for i in range(len(labels)):\n",
    "        cluster = labels[i]\n",
    "        member = stocks[i]\n",
    "        if cluster not in cluster_dict.keys():\n",
    "            cluster_dict[cluster] = []\n",
    "        cluster_dict[cluster].append(member)\n",
    "    return cluster_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trading(\n",
    "        prices_dataframe, caps_dataframe, market_dictionary, \n",
    "        available_sector_list, num_clusters, num_sectors, n_market_cap, n_cv, \n",
    "        consider_cv, cluster, cluster_method, final_beta_validation,\n",
    "        run_frequency, n_runs, n_initializations, record_clustering, record_stock_selection):\n",
    "    #### Setup\n",
    "    all_dates_list = prices_dataframe.index.tolist() # full list of all dates\n",
    "    trading_results_dict = {} # records trades\n",
    "    stocks_currently_in_trade = []\n",
    "    if record_clustering == 'Yes':\n",
    "        clustering_output_data = []\n",
    "    if record_stock_selection == 'Yes':\n",
    "        Stocks_considered_record = {} # records the stock selection\n",
    "\n",
    "    ### Find the available dates/periods\n",
    "    dates_dictionary = {}\n",
    "    period_counter = 0\n",
    "    current_first_day = ''\n",
    "    for i in range(len(all_dates_list)):\n",
    "        if (i+1) < len(all_dates_list):\n",
    "            current_day = all_dates_list[i]\n",
    "            next_day = all_dates_list[(i+1)]\n",
    "            if i == 0:\n",
    "                current_first_day = current_day\n",
    "            if run_frequency == 'Monthly':\n",
    "                current_day_month = current_day.month\n",
    "                next_day_month = next_day.month\n",
    "                if current_day_month != next_day_month:\n",
    "                    #print(current_first_day, current_day)\n",
    "                    dates_dictionary[period_counter] = (current_first_day, current_day)\n",
    "                    current_first_day = next_day\n",
    "                    period_counter += 1\n",
    "            elif run_frequency == 'Weekly':\n",
    "                current_day_week = current_day.isocalendar().week\n",
    "                next_day_week = next_day.isocalendar().week\n",
    "                if next_day_week != current_day_week:\n",
    "                    #print(current_first_day, current_day)\n",
    "                    dates_dictionary[period_counter] = (current_first_day, current_day)\n",
    "                    current_first_day = next_day\n",
    "                    period_counter += 1\n",
    "            else:\n",
    "                print('Error: Invalid run_frequency entered, please choose (\"Monthly\"/\"Weekly\")')\n",
    "                return 0\n",
    "\n",
    "    ### decide how long to run\n",
    "    total_runs = 0\n",
    "    if n_runs == 'Max':\n",
    "        total_runs = len(dates_dictionary)\n",
    "    else:\n",
    "        total_runs = int(n_runs)\n",
    "    \n",
    "    #### Main function\n",
    "    for i in range(total_runs):\n",
    "        first_day_of_period, last_day_of_period = dates_dictionary[i]\n",
    "\n",
    "        ### Trading pt1: close existing trades\n",
    "        #print('...closing_trades...')\n",
    "        #print(f'Stocks currently in trade: {stocks_currently_in_trade}')\n",
    "        if len(stocks_currently_in_trade) > 0: # are there any?\n",
    "            for trading_stock in stocks_currently_in_trade: # iterate over the list\n",
    "                # close the trade\n",
    "                open_price = trading_results_dict[trading_stock]['Open_price'][-1]\n",
    "                close_price = prices_dataframe.loc[last_day_of_period, trading_stock]\n",
    "                if pd.isna(close_price): # iterate backward\n",
    "                    index_position = all_dates_list.index(last_day_of_period) # Find the current index in index_dict\n",
    "                    while pd.isna(close_price) and index_position > 0:\n",
    "                        index_position -= 1\n",
    "                        close_price = prices_dataframe.loc[all_dates_list[index_position], trading_stock]\n",
    "                trading_results_dict[trading_stock]['Close_date'].append(last_day_of_period)\n",
    "                trading_results_dict[trading_stock]['Close_price'].append(close_price)\n",
    "                if trading_results_dict[trading_stock]['Trade_type'][-1] == 'Short':\n",
    "                    profit = (open_price-close_price)/open_price\n",
    "                else: # 'Long'\n",
    "                    profit = (close_price-open_price)/open_price\n",
    "                trading_results_dict[trading_stock]['Profit'].append(profit)\n",
    "                #print(trading_stock)\n",
    "        stocks_currently_in_trade = []\n",
    "\n",
    "        ### Stock & Sector Selection\n",
    "        new_stocks_considered_row = {}\n",
    "        sectors_to_consider = []\n",
    "        if num_sectors == len(available_sector_list):\n",
    "            sectors_to_consider = available_sector_list\n",
    "        else:\n",
    "            sector_cap_dictionary = {}\n",
    "            for sctr in available_sector_list:\n",
    "                sctr_stocks = market_dictionary[sctr]\n",
    "                sector_df = caps_dataframe[sctr_stocks][first_day_of_period:last_day_of_period]\n",
    "                sector_df = sector_df.dropna(axis=1)\n",
    "                mean_cap = sector_df.values.mean()\n",
    "                sector_cap_dictionary[sctr] = mean_cap\n",
    "            ranked_sectors = sorted(sector_cap_dictionary.items(), key=lambda item: item[1], reverse=True)\n",
    "            ranked_sectors = ranked_sectors[:num_sectors]\n",
    "            for s_tpl in ranked_sectors:\n",
    "                sectors_to_consider.append(s_tpl[0])\n",
    "        if len(sectors_to_consider) != num_sectors:\n",
    "            print('Warning: Not enough sectors found')\n",
    "            print('--------------------------------')\n",
    "            print(sectors_to_consider)\n",
    "        if pd.Series(sectors_to_consider).nunique() != num_sectors:\n",
    "            print('Warning: Duplicate sectors found')\n",
    "            print('--------------------------------')\n",
    "            print(sectors_to_consider)\n",
    "\n",
    "        stocks_to_consider = []\n",
    "        price_data = prices_dataframe[first_day_of_period:last_day_of_period]\n",
    "        caps_data = caps_dataframe[first_day_of_period:last_day_of_period]\n",
    "        for sector in sectors_to_consider:\n",
    "            new_stocks_considered_row[sector] = []\n",
    "            sector_stocks_unchecked = market_dictionary[sector]\n",
    "            sector_stocks_non_null = []\n",
    "            sector_stocks = []\n",
    "            for stoc in sector_stocks_unchecked:\n",
    "                if price_data[stoc].isna().any() != True:\n",
    "                    sector_stocks_non_null.append(stoc)\n",
    "            if len(sector_stocks_non_null) < n_market_cap:\n",
    "                print(f'Warning: Less than {n_market_cap} non-null stocks found')\n",
    "                print('-----------------------------------------------------------')\n",
    "                print(f'sector: {sector}')\n",
    "                print(f'stocks non-null: {sector_stocks_non_null}')  \n",
    "            for stoc in sector_stocks_non_null:\n",
    "                if price_data[stoc].nunique() != 1:\n",
    "                    sector_stocks.append(stoc)\n",
    "            if len(sector_stocks) < n_market_cap:\n",
    "                print(f'Warning: Less than {n_market_cap} non-const stocks found')\n",
    "                print('-----------------------------------------------------------')\n",
    "                print(f'sector: {sector}')\n",
    "                print(f'stocks non-const: {sector_stocks}')\n",
    "                print(price_data[sector_stocks_non_null])  \n",
    "            top_cap_stocks = list(caps_data[sector_stocks].mean().nlargest(n_market_cap).index)\n",
    "            if consider_cv == 'Yes':\n",
    "                stocks_cv_dict = {}\n",
    "                for stk in top_cap_stocks:\n",
    "                    std_dev = float(np.std(price_data[stk]))\n",
    "                    mean = float(np.mean(price_data[stk]))\n",
    "                    cv = std_dev/mean\n",
    "                    stocks_cv_dict[stk] = cv\n",
    "                least_varied = sorted(stocks_cv_dict.items(), key=lambda x:x[1])[:n_cv]\n",
    "                for stk_tpl in least_varied:\n",
    "                    stk_name = stk_tpl[0]\n",
    "                    stocks_to_consider.append(stk_name)\n",
    "                    new_stocks_considered_row[sector].append(stk_name)\n",
    "            else:\n",
    "                for stk in top_cap_stocks:\n",
    "                    stocks_to_consider.append(stk)\n",
    "                    new_stocks_considered_row[sector].append(stk)\n",
    "        Stocks_considered_record[first_day_of_period] = new_stocks_considered_row\n",
    "\n",
    "        ### Clustering \n",
    "        possible_missclassified_stocks = []\n",
    "        if cluster == 'Yes':\n",
    "            if cluster_method == 'KMeans':\n",
    "                cluster_entry = K_mean_clustering(price_data[stocks_to_consider], num_clusters, n_init=n_initializations)\n",
    "            elif cluster_method == 'Spectral':\n",
    "                cluster_entry = spectral_clustering(price_data[stocks_to_consider], num_clusters)\n",
    "            elif cluster_method == 'Hierarchial':\n",
    "                cluster_entry = Hierarchical_clustering(price_data[stocks_to_consider], num_clusters)\n",
    "            for cluster_name in list(cluster_entry.keys()): # iterate over the n clusters\n",
    "                # pull the members and sort the sectors\n",
    "                cluster_members = cluster_entry[cluster_name]\n",
    "                #new_clustering_row[f'Cluster_{int(cluster_name)+1}_Members'] = cluster_members\n",
    "                cluster_members_dict = {}\n",
    "                cluster_sectors = []\n",
    "                for stk in cluster_members:\n",
    "                    for sctr in market_dictionary:\n",
    "                        stocks_list = market_dictionary[sctr]\n",
    "                        if stk in stocks_list:\n",
    "                            if sctr not in cluster_sectors:\n",
    "                                cluster_sectors.append(sctr)\n",
    "                for sctr in cluster_sectors:\n",
    "                    cluster_members_dict[sctr] = []\n",
    "                for stk in cluster_members:\n",
    "                    for sctr in market_dictionary:\n",
    "                        stocks_list = market_dictionary[sctr]\n",
    "                        if stk in stocks_list:\n",
    "                            cluster_members_dict[sctr].append(stk)\n",
    "                # identify misclassified stocks\n",
    "                if len(cluster_sectors) > 1:\n",
    "                    sctr_lengths = np.array([len(value_list) for value_list in cluster_members_dict.values()])\n",
    "                    even_split = np.all(sctr_lengths == sctr_lengths[0])\n",
    "                    if even_split == False:\n",
    "                        cluster_members_cnt_dict = {}\n",
    "                        for sctr in cluster_members_dict:\n",
    "                            cluster_members_cnt_dict[sctr] = len(cluster_members_dict[sctr])\n",
    "                        highest_num_stks = max(cluster_members_cnt_dict.values())\n",
    "                        lowest_num_stks = min(cluster_members_cnt_dict.values())\n",
    "                        has_majority = list(cluster_members_cnt_dict.values()).count(highest_num_stks) == 1\n",
    "                        has_minority = list(cluster_members_cnt_dict.values()).count(lowest_num_stks) == 1\n",
    "                        if has_majority:\n",
    "                            if has_minority:\n",
    "                                minority_sctr = [sctr for sctr, count in cluster_members_cnt_dict.items() if count == lowest_num_stks][0]\n",
    "                                minority_stks = cluster_members_dict[minority_sctr]  \n",
    "                                if len(minority_stks) == 1:\n",
    "                                    possible_missclassified_stocks.append(minority_stks[0]) \n",
    "\n",
    "        ### Trading pt2: new trades\n",
    "        #print('...opening_trades...')\n",
    "        stocks_to_trade = []\n",
    "        if cluster == 'Yes':\n",
    "            for minority_stk in possible_missclassified_stocks:\n",
    "                if final_beta_validation == 'Yes':\n",
    "                    # find the minority stocks sector\n",
    "                    minority_sctr = ''\n",
    "                    for sctr in market_dictionary:\n",
    "                        sctrs_stocks = market_dictionary[sctr]\n",
    "                        if minority_stk in sctrs_stocks:\n",
    "                            minority_sctr = sctr\n",
    "                            break\n",
    "                    # view its peers and view their behavior, trade or not accordingly \n",
    "                    minority_sctr_stks = market_dictionary[minority_sctr]\n",
    "                    peer_stocks = []\n",
    "                    for possible_peer_stock in stocks_to_consider:\n",
    "                        if possible_peer_stock in minority_sctr_stks:\n",
    "                            peer_stocks.append(possible_peer_stock)\n",
    "                    peer_stocks.remove(minority_stk)\n",
    "                    up_cntr = 0\n",
    "                    down_cntr = 0\n",
    "                    for peer_stk in peer_stocks:\n",
    "                        stk_price_data = price_data[peer_stk]\n",
    "                        covariance = np.cov(range(len(stk_price_data)), stk_price_data.values)\n",
    "                        beta = covariance[0,1]\n",
    "                        if beta > 0:\n",
    "                            up_cntr +=1\n",
    "                        else:\n",
    "                            down_cntr +=1\n",
    "                    if (up_cntr == 0) or (down_cntr == 0):\n",
    "                        if up_cntr > 0: # peers are going up\n",
    "                            # check if the minority is going down\n",
    "                            minority_stk_price_data = price_data[minority_stk]\n",
    "                            covariance = np.cov(range(len(minority_stk_price_data)), minority_stk_price_data.values)\n",
    "                            beta = covariance[0,1]\n",
    "                            if beta < 0:\n",
    "                                stocks_to_trade.append((minority_stk, 'Long'))\n",
    "                        elif down_cntr > 0: # peers are going down\n",
    "                            # check if the minority is going up\n",
    "                            minority_stk_price_data = price_data[minority_stk]\n",
    "                            covariance = np.cov(range(len(minority_stk_price_data)), minority_stk_price_data.values)\n",
    "                            beta = covariance[0,1]\n",
    "                            if beta < 0:\n",
    "                                stocks_to_trade.append((minority_stk, 'Short'))\n",
    "                else:\n",
    "                    minority_stk_price_data = price_data[minority_stk]\n",
    "                    covariance = np.cov(range(len(minority_stk_price_data)), minority_stk_price_data.values)\n",
    "                    beta = covariance[0,1]\n",
    "                    if beta > 0: # short\n",
    "                        stocks_to_trade.append((minority_stk, 'Short'))\n",
    "                    else: # long\n",
    "                        stocks_to_trade.append((minority_stk, 'Long'))\n",
    "        else: # we didn't use clustering\n",
    "            for sctr in list(new_stocks_considered_row.keys()):\n",
    "                sctrs_stocks = new_stocks_considered_row[sctr]\n",
    "                sctrs_stocks_direction = {\n",
    "                    'Up': [],\n",
    "                    'Down': []\n",
    "                }\n",
    "                for stk in sctrs_stocks:\n",
    "                    stk_price_data = price_data[stk]\n",
    "                    covariance = np.cov(range(len(stk_price_data)), stk_price_data.values)\n",
    "                    beta = covariance[0,1]\n",
    "                    if beta > 0:\n",
    "                        sctrs_stocks_direction['Up'].append(stk)\n",
    "                    else:\n",
    "                        sctrs_stocks_direction['Down'].append(stk)\n",
    "                if len(sctrs_stocks_direction['Up']) == 1: # short\n",
    "                    stocks_to_trade.append((sctrs_stocks_direction['Up'][0], 'Short'))\n",
    "                if len(sctrs_stocks_direction['Down']) == 1: # long\n",
    "                    stocks_to_trade.append((sctrs_stocks_direction['Down'][0], 'Long'))\n",
    "        #print(f'Stocks to trade: {stocks_to_trade}')\n",
    "        if len(stocks_to_trade) > 0:\n",
    "            for trading_stock_tpl in stocks_to_trade:\n",
    "                stk_name = trading_stock_tpl[0]\n",
    "                trading_direction = trading_stock_tpl[1]\n",
    "                current_price = price_data.loc[last_day_of_period, stk_name]\n",
    "                if stk_name in list(trading_results_dict.keys()):\n",
    "                    trading_results_dict[stk_name]['Open_date'].append(last_day_of_period)\n",
    "                    trading_results_dict[stk_name]['Trade_type'].append(trading_direction)\n",
    "                    trading_results_dict[stk_name]['Open_price'].append(current_price)\n",
    "                else: \n",
    "                    trading_results_dict[stk_name] = {\n",
    "                        'Open_date':[last_day_of_period],\n",
    "                        'Close_date':[],\n",
    "                        'Trade_type':[trading_direction],\n",
    "                        'Open_price':[current_price],\n",
    "                        'Close_price':[],\n",
    "                        'Profit':[],\n",
    "                        }\n",
    "                #print(stk_name)\n",
    "                stocks_currently_in_trade.append(stk_name)   \n",
    "                \n",
    "    return trading_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_list = ['Industrials',\n",
    "    'Finance',\n",
    "    'Real Estate',\n",
    "    'Health Care', \n",
    "    'Consumer Discretionary',\n",
    "    'Technology',\n",
    "    'Basic Materials',\n",
    "    'Consumer Staples',\n",
    "    'Energy',\n",
    "    'Utilities',\n",
    "    'Telecommunications'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cum_sum_plot_single(trading_results):\n",
    "    # Get all the possible timestamps\n",
    "    all_timestamps = sorted(set(ts for stock in trading_results for ts in trading_results[stock]['Close_date']))\n",
    "    temp_data = {\n",
    "        'Time': all_timestamps,\n",
    "        'Cumulative_Sum': []\n",
    "    }\n",
    "    cum_sum = 0\n",
    "    for timestamp in all_timestamps:\n",
    "        # Find profits for this timestamp\n",
    "        profits = []\n",
    "        for stock in trading_results:\n",
    "            for index_pos, ts in enumerate(trading_results[stock]['Close_date']):\n",
    "                if ts == timestamp:\n",
    "                    profits.append(trading_results[stock]['Profit'][index_pos])\n",
    "        # Ensure cumulative sum is increasing correctly\n",
    "        cum_sum += np.sum(profits)\n",
    "        temp_data['Cumulative_Sum'].append(cum_sum)\n",
    "    return pd.DataFrame(temp_data).set_index('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cum_sum_plot_multiple(*trading_results):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i, results in enumerate(trading_results):\n",
    "        all_timestamps = sorted(set(ts for stock in results for ts in results[stock]['Close_date']))    \n",
    "        temp_data = {\n",
    "            'Time': all_timestamps,\n",
    "            'Cumulative_Sum': []\n",
    "        }\n",
    "        cum_sum = 0\n",
    "        for timestamp in all_timestamps:\n",
    "            profits = []\n",
    "            for stock in results:\n",
    "                for index_pos, ts in enumerate(results[stock]['Close_date']):\n",
    "                    if ts == timestamp:\n",
    "                        profits.append(results[stock]['Profit'][index_pos])\n",
    "            \n",
    "            cum_sum += np.sum(profits)\n",
    "            temp_data['Cumulative_Sum'].append(cum_sum)\n",
    "\n",
    "        df = pd.DataFrame(temp_data).set_index('Time')\n",
    "        # Plot each dataset with a unique label\n",
    "        plt.plot(df.index, df['Cumulative_Sum'], label=f'Num Sectors: {i+2}')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Cumulative Sum')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trading_check_spreads(\n",
    "        prices_dataframe, caps_dataframe, market_dictionary, \n",
    "        sector_order, num_clusters, num_sectors, n_market_cap, n_cv, \n",
    "        consider_cv, cluster, cluster_method, cluster_beta_validation,\n",
    "        num_months_to_run, run_frequency, n_iterations, initializations_list):\n",
    "    spread_series_dictionary = {}\n",
    "    for i_1 in range(n_iterations):\n",
    "        print(f'Iteration {i_1+1}:')\n",
    "        trading_results_dict = {}\n",
    "        number_initializations = initializations_list[i_1]\n",
    "        for i_2 in range(3):\n",
    "            print(f'-- Run {i_2+1}')\n",
    "            Stocks_considered, clustering_res, trading_res = trading(\n",
    "                prices_dataframe=prices_dataframe, caps_dataframe=caps_dataframe, \n",
    "                market_dictionary=market_dictionary, sector_order=sector_order,\n",
    "                num_clusters=num_clusters, num_sectors=num_sectors, n_market_cap=n_market_cap,\n",
    "                n_cv=n_cv, consider_cv=consider_cv, cluster=cluster, cluster_method=cluster_method,\n",
    "                cluster_beta_validation=cluster_beta_validation, num_months_to_run=num_months_to_run,\n",
    "                run_frequency=run_frequency, n_init=number_initializations\n",
    "            )\n",
    "            cum_sum_series = cum_sum_plot_single(trading_res)\n",
    "            trading_results_dict[f'Run_{i_2}'] = cum_sum_series\n",
    "        temp_df = pd.concat(trading_results_dict, axis=1)\n",
    "        temp_df.interpolate(method='time', inplace=True)\n",
    "        spread_series = temp_df.max(axis=1) - temp_df.min(axis=1)\n",
    "        #temp_df.plot(title=f'KMeans Cumulative Sums({n_iterations} Iterations)', legend=False)\n",
    "        spread_series_dictionary[f'Init_{number_initializations}'] = spread_series\n",
    "    temp_df_2 = pd.concat(spread_series_dictionary, axis=1)\n",
    "    temp_df_2.plot(legend=True)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Spread')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trading_KMeans_1(run_frequency, n_runs):\n",
    "    trading_results_dict = {}\n",
    "    n_iterations = 5\n",
    "    for i in range(n_iterations):\n",
    "        Stocks_considered, clustering_res, trading_res = trading(\n",
    "            prices_dataframe=train_df, caps_dataframe=caps_df, \n",
    "            market_dictionary=full_market_dict, sector_order=sector_order, \n",
    "            num_clusters=7, num_sectors=7, n_market_cap=10, n_cv=4, consider_cv='Yes',\n",
    "            cluster='Yes', cluster_beta_validation='no', cluster_method='KMeans',\n",
    "            num_months_to_run=n_runs, run_frequency=run_frequency, n_init=20)\n",
    "        cum_sum_series = cum_sum_plot_single(trading_res)\n",
    "        trading_results_dict[f'Run_{i}'] = cum_sum_series\n",
    "    temp_df = pd.concat(trading_results_dict, axis=1)\n",
    "    temp_df.plot(title=f'KMeans Cumlative Sums({n_iterations} Iterations)', legend=False)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Cumlative Sum\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trading_Spectral(run_frequency, n_runs):\n",
    "    trading_results_dict = {}\n",
    "    n_iterations = 5\n",
    "    for i in range(n_iterations):\n",
    "        Stocks_considered, clustering_res, trading_res = trading(\n",
    "            prices_dataframe=train_df, caps_dataframe=caps_df, \n",
    "            market_dictionary=full_market_dict, sector_order=sector_order, \n",
    "            num_clusters=7, num_sectors=7, n_market_cap=10, n_cv=4, consider_cv='Yes',\n",
    "            cluster='Yes', cluster_beta_validation='no', cluster_method='Spectral',\n",
    "            num_months_to_run=n_runs, run_frequency=run_frequency, n_init=20)\n",
    "        cum_sum_series = cum_sum_plot_single(trading_res)\n",
    "        trading_results_dict[f'Run_{i}'] = cum_sum_series\n",
    "    temp_df = pd.concat(trading_results_dict, axis=1)\n",
    "    temp_df.plot(title=f'Spectral Cumlative Sums({n_iterations} Iterations)', legend=False)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Cumlative Sum\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trading_Hierarchial(run_frequency, n_runs):\n",
    "    trading_results_dict = {}\n",
    "    n_iterations = 5\n",
    "    for i in range(n_iterations):\n",
    "        Stocks_considered, clustering_res, trading_res = trading(\n",
    "            prices_dataframe=train_df, caps_dataframe=caps_df, \n",
    "            market_dictionary=full_market_dict, sector_order=sector_order, \n",
    "            num_clusters=7, num_sectors=7, n_market_cap=10, n_cv=4, consider_cv='Yes',\n",
    "            cluster='Yes', cluster_beta_validation='no', cluster_method='Hierarchial',\n",
    "            num_months_to_run=n_runs, run_frequency=run_frequency, n_init=20)\n",
    "        cum_sum_series = cum_sum_plot_single(trading_res)\n",
    "        trading_results_dict[f'Run_{i}'] = cum_sum_series\n",
    "    temp_df = pd.concat(trading_results_dict, axis=1)\n",
    "    temp_df.plot(title=f'Hierarchial Cumlative Sums({n_iterations} Iterations)', legend=False)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Cumlative Sum\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trading_noCluster(run_frequency, n_runs):\n",
    "    trading_results_dict = {}\n",
    "    n_iterations = 1\n",
    "    for i in range(n_iterations):\n",
    "        #print(f'Iteration: {i}')\n",
    "        Stocks_considered, clustering_res, trading_res = trading(\n",
    "            prices_dataframe=train_df, caps_dataframe=caps_df, \n",
    "            market_dictionary=full_market_dict, sector_order=sector_order, \n",
    "            num_clusters=7, num_sectors=7, n_market_cap=10, n_cv=4, consider_cv='Yes',\n",
    "            cluster='No', cluster_beta_validation='no', cluster_method='Hierarchial',\n",
    "            num_months_to_run=n_runs, run_frequency=run_frequency, n_init=20)\n",
    "        cum_sum_series = cum_sum_plot_single(trading_res)\n",
    "        trading_results_dict[f'Run_{i}'] = cum_sum_series\n",
    "    temp_df = pd.concat(trading_results_dict, axis=1)\n",
    "    temp_df.plot(title=f'No Clustering Cumlative Sums({n_iterations} Iterations)', legend=False)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Cumlative Sum\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSFT': {'Open_date': [Timestamp('2000-08-31 00:00:00')],\n",
       "  'Close_date': [Timestamp('2000-09-29 00:00:00')],\n",
       "  'Trade_type': ['Long'],\n",
       "  'Open_price': [21.684],\n",
       "  'Close_price': [18.734],\n",
       "  'Profit': [-0.13604501014572953]},\n",
       " 'WMT': {'Open_date': [Timestamp('2000-10-31 00:00:00')],\n",
       "  'Close_date': [],\n",
       "  'Trade_type': ['Long'],\n",
       "  'Open_price': [29.686],\n",
       "  'Close_price': [],\n",
       "  'Profit': []}}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trading(prices_dataframe=train_df, caps_dataframe=caps_df, market_dictionary=full_market_dict,\n",
    "        available_sector_list=sector_list, num_clusters=7, num_sectors=7,\n",
    "        n_market_cap=10, n_cv=4, consider_cv='Yes', cluster='Yes', \n",
    "        cluster_method='KMeans', final_beta_validation='Yes', run_frequency='Monthly', \n",
    "        n_initializations=20, record_clustering='Yes', record_stock_selection='Yes', n_runs='10')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
