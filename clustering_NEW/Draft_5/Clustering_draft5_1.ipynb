{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from numpy import linalg as LA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from itertools import combinations\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "import random\n",
    "import matplotlib.gridspec as gridspec\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.collections as mcollections\n",
    "from scipy.cluster.hierarchy import dendrogram, cut_tree\n",
    "from ISLP.cluster import compute_linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_path = '/Users/tuckeringlefield/Desktop/Data_Science/Math_4920/Stocks_Data/cap_data_from_shardar.csv'\n",
    "price_path = \"/Users/tuckeringlefield/Desktop/Data_Science/Math_4920/Stocks_Data/price_data_from_shardar.csv\"\n",
    "\n",
    "# Reading Data:\n",
    "prices_df = pd.read_csv(price_path, index_col='date')\n",
    "prices_df.index = pd.to_datetime(prices_df.index)\n",
    "caps_df = pd.read_csv(cap_path, index_col='date')\n",
    "caps_df.index = pd.to_datetime(caps_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Length: 5787\n",
      "Train Length: 2894\n"
     ]
    }
   ],
   "source": [
    "# Pulling rougly the first half of data\n",
    "num_rows = len(prices_df)\n",
    "print(f'Original Length: {num_rows}')\n",
    "train_df = prices_df[:np.round(num_rows/2).astype(int)]\n",
    "caps_df = caps_df[:np.round(num_rows/2).astype(int)]\n",
    "num_rows = len(train_df)\n",
    "print(f'Train Length: {num_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10810\n",
      "2467\n"
     ]
    }
   ],
   "source": [
    "# Let's identify stocks with no null values\n",
    "complete_stock_list = train_df.columns\n",
    "non_null_stocks = []\n",
    "for stock in complete_stock_list:\n",
    "    # get the count of nulls\n",
    "    null_count = train_df[stock].isnull().sum()\n",
    "    if null_count == 0:\n",
    "        non_null_stocks.append(stock)\n",
    "\n",
    "print(len(complete_stock_list))\n",
    "print(len(non_null_stocks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Market_dict = {}\n",
    "file_path = '/Users/tuckeringlefield/Desktop/Data_Science/Math_4920/Stocks_Data/Nasdaq_sectors.csv'\n",
    "nasdaq_sectors = pd.read_csv(file_path)\n",
    "cols_to_keep = ['Symbol', 'Sector']\n",
    "nasdaq_sectors = nasdaq_sectors[cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Sector in nasdaq_sectors['Sector'].unique().tolist():\n",
    "    if pd.notna(Sector):\n",
    "        Market_dict[Sector] = []\n",
    "        temp_df = nasdaq_sectors[nasdaq_sectors['Sector']==Sector]\n",
    "        for stk in temp_df['Symbol'].unique().tolist():\n",
    "            if stk in complete_stock_list:\n",
    "                Market_dict[Sector].append(stk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Industrials\n",
      "343\n",
      "Finance\n",
      "430\n",
      "Real Estate\n",
      "101\n",
      "Health Care\n",
      "679\n",
      "Consumer Discretionary\n",
      "630\n",
      "Technology\n",
      "414\n",
      "Basic Materials\n",
      "19\n",
      "Consumer Staples\n",
      "75\n",
      "Energy\n",
      "100\n",
      "Miscellaneous\n",
      "24\n",
      "Utilities\n",
      "73\n",
      "Telecommunications\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "for Sector in list(Market_dict.keys()):\n",
    "    print(Sector)\n",
    "    print(len(Market_dict[Sector]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_market_dict = Market_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
