{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from numpy import linalg as LA\n",
    "from sklearn.cluster import KMeans\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from itertools import combinations\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "import random\n",
    "import matplotlib.gridspec as gridspec\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.collections as mcollections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_path = '/Users/tuckeringlefield/Desktop/Data_Science/Math_4920/Stocks_Data/cap_data_from_shardar.csv'\n",
    "price_path = \"/Users/tuckeringlefield/Desktop/Data_Science/Math_4920/Stocks_Data/price_data_from_shardar.csv\"\n",
    "\n",
    "# Reading Data:\n",
    "prices_df = pd.read_csv(price_path, index_col='date')\n",
    "prices_df.index = pd.to_datetime(prices_df.index)\n",
    "caps_df = pd.read_csv(cap_path, index_col='date')\n",
    "caps_df.index = pd.to_datetime(caps_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Length: 5787\n",
      "Train Length: 2894\n"
     ]
    }
   ],
   "source": [
    "# Pulling rougly the first half of data\n",
    "num_rows = len(prices_df)\n",
    "print(f'Original Length: {num_rows}')\n",
    "train_df = prices_df[:np.round(num_rows/2).astype(int)]\n",
    "caps_df = caps_df[:np.round(num_rows/2).astype(int)]\n",
    "num_rows = len(train_df)\n",
    "print(f'Train Length: {num_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10810\n",
      "2467\n"
     ]
    }
   ],
   "source": [
    "# Let's identify stocks with no null values\n",
    "complete_stock_list = train_df.columns\n",
    "non_null_stocks = []\n",
    "for stock in complete_stock_list:\n",
    "    # get the count of nulls\n",
    "    null_count = train_df[stock].isnull().sum()\n",
    "    if null_count == 0:\n",
    "        non_null_stocks.append(stock)\n",
    "\n",
    "print(len(complete_stock_list))\n",
    "print(len(non_null_stocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[non_null_stocks]\n",
    "caps_df = caps_df[non_null_stocks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Market_dict = {}\n",
    "file_path = '/Users/tuckeringlefield/Desktop/Data_Science/Math_4920/Stocks_Data/Nasdaq_sectors.csv'\n",
    "nasdaq_sectors = pd.read_csv(file_path)\n",
    "cols_to_keep = ['Symbol', 'Sector']\n",
    "nasdaq_sectors = nasdaq_sectors[cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Sector in nasdaq_sectors['Sector'].unique().tolist():\n",
    "    if pd.notna(Sector):\n",
    "        Market_dict[Sector] = []\n",
    "        temp_df = nasdaq_sectors[nasdaq_sectors['Sector']==Sector]\n",
    "        for stk in temp_df['Symbol'].unique().tolist():\n",
    "            if stk in non_null_stocks:\n",
    "                Market_dict[Sector].append(stk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Industrials\n",
      "202\n",
      "Finance\n",
      "186\n",
      "Real Estate\n",
      "42\n",
      "Health Care\n",
      "124\n",
      "Consumer Discretionary\n",
      "275\n",
      "Technology\n",
      "139\n",
      "Basic Materials\n",
      "13\n",
      "Consumer Staples\n",
      "40\n",
      "Energy\n",
      "47\n",
      "Miscellaneous\n",
      "9\n",
      "Utilities\n",
      "43\n",
      "Telecommunications\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "for Sector in list(Market_dict.keys()):\n",
    "    print(Sector)\n",
    "    print(len(Market_dict[Sector]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_market_dict = Market_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr_matrix(DataFrame):\n",
    "    return DataFrame.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_mean_clustering(DataFrame, num_clusters):\n",
    "    X = get_corr_matrix(DataFrame)\n",
    "    kmeans = KMeans(n_clusters=num_clusters, n_init=20).fit(X)\n",
    "    cluster_dict = {}\n",
    "    # Iterate over the indices of cluster_list\n",
    "    for i in range(len(kmeans.labels_)):\n",
    "        cluster_number = kmeans.labels_[i]\n",
    "        stock_name = DataFrame.columns[i]\n",
    "        # Check if cluster_number is already a key in the dictionary\n",
    "        if cluster_number in cluster_dict:\n",
    "            cluster_dict[cluster_number].append(stock_name)\n",
    "        else:\n",
    "            cluster_dict[cluster_number] = [stock_name]\n",
    "    return cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_clustering(df, num_clusters):\n",
    "    A = abs(df.corr().values)\n",
    "    #A = df.corr().values\n",
    "    D = np.diag(A.sum(axis=1))\n",
    "    L = D - A\n",
    "    eigenvalues, eigenvectors = LA.eig(L)\n",
    "    X = eigenvectors[:,:num_clusters]\n",
    "    kmeans = KMeans(n_clusters=num_clusters, n_init=20).fit(X)\n",
    "    cluster_dict = {}\n",
    "    # Iterate over the indices of cluster_list\n",
    "    for i in range(len(kmeans.labels_)):\n",
    "        cluster_number = kmeans.labels_[i]\n",
    "        stock_name = df.columns[i]\n",
    "        # Check if cluster_number is already a key in the dictionary\n",
    "        if cluster_number in cluster_dict:\n",
    "            cluster_dict[cluster_number].append(stock_name)\n",
    "        else:\n",
    "            cluster_dict[cluster_number] = [stock_name]\n",
    "    return cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heirarchial_clustering(df, num_clusters):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trading(\n",
    "        prices_dataframe, caps_dataframe, market_dictionary, \n",
    "        sector_order, num_clusters, num_sectors, n_market_cap, n_cv, \n",
    "        consider_cv, cluster, cluster_method, cluster_beta_validation,\n",
    "        num_months_to_run):\n",
    "    #### Setup\n",
    "    clustering_output_data = [] # records the clustering results\n",
    "    index_list = prices_dataframe.index.tolist() # full list of dates\n",
    "    first_day = index_list[0] # start out on the correct day\n",
    "    trading_results_dict = {} # records trades\n",
    "    stocks_currently_in_trade = [] # keeps track of stocks in trade\n",
    "    Stocks_considered_record = {} # records the stock selection\n",
    "\n",
    "    #### Monthly Iteration\n",
    "    for _ in range(num_months_to_run):\n",
    "        #print('-------------new_month-------------')\n",
    "        #print(f'Stocks currently in trade: {stocks_currently_in_trade}')\n",
    "        ### Setup\n",
    "        new_clustering_row = {}\n",
    "        last_day_of_month = pd.Timestamp(first_day.year, first_day.month, 1) + pd.offsets.MonthEnd(0)\n",
    "        last_day_position = None\n",
    "        current_last_day = last_day_of_month \n",
    "        new_clustering_row['timestamp'] = current_last_day\n",
    "        while last_day_position is None: # Keep searching until we find a valid index position for the last day of the month\n",
    "            try:\n",
    "                last_day_position = next(\n",
    "                    i for i, t in enumerate(index_list) if t.date() == current_last_day.date()\n",
    "                )\n",
    "            except StopIteration:\n",
    "                current_last_day -= pd.Timedelta(days=1) # Backtrack by one day and try again if not found\n",
    "                if current_last_day < first_day: # If backtracking goes too far, raise an error\n",
    "                    raise ValueError(\n",
    "                        f\"Could not find a suitable last day for the month starting at {first_day}. \"\n",
    "                        \"Backtracking exceeded the first day.\"\n",
    "                    )\n",
    "        next_day = current_last_day + pd.Timedelta(days=1) # Move to the next day after the last day of this month\n",
    "        while next_day not in index_list: # Keep moving to the next day until a valid first day is found\n",
    "            next_day += pd.Timedelta(days=1)\n",
    "\n",
    "        ### Trading pt1: close existing trades\n",
    "        #print('...closing_trades...')\n",
    "        #print(f'Stocks currently in trade: {stocks_currently_in_trade}')\n",
    "        if len(stocks_currently_in_trade) > 0: # are there any?\n",
    "            for trading_stock in stocks_currently_in_trade: # iterate over the list\n",
    "                # close the trade\n",
    "                open_price = trading_results_dict[trading_stock]['Open_price'][-1]\n",
    "                close_price = prices_dataframe.loc[current_last_day, trading_stock]\n",
    "                trading_results_dict[trading_stock]['Close_date'].append(current_last_day)\n",
    "                trading_results_dict[trading_stock]['Close_price'].append(close_price)\n",
    "                if trading_results_dict[trading_stock]['Trade_type'][-1] == 'Short':\n",
    "                    profit = (open_price-close_price)/open_price\n",
    "                else: # 'Long'\n",
    "                    profit = (close_price-open_price)/open_price\n",
    "                trading_results_dict[trading_stock]['Profit'].append(profit)\n",
    "                #print(trading_stock)\n",
    "        stocks_currently_in_trade = []\n",
    "\n",
    "        ### Stock Selection\n",
    "        new_stocks_considered_row = {}\n",
    "        sectors_to_consider = sector_order[:num_sectors]\n",
    "        stocks_to_consider = []\n",
    "        monthly_price_data = prices_dataframe[first_day:current_last_day]\n",
    "        monthly_caps_data = caps_dataframe[first_day:current_last_day]\n",
    "        for sector in sectors_to_consider:\n",
    "            new_stocks_considered_row[sector] = []\n",
    "            sector_stocks = market_dictionary[sector]\n",
    "            top_cap_stocks = list(monthly_caps_data[sector_stocks].mean().nlargest(n_market_cap).index)\n",
    "            if consider_cv == 'Yes':\n",
    "                stocks_cv_dict = {}\n",
    "                for stk in top_cap_stocks:\n",
    "                    std_dev = float(np.std(monthly_price_data[stk]))\n",
    "                    mean = float(np.mean(monthly_price_data[stk]))\n",
    "                    cv = std_dev/mean\n",
    "                    stocks_cv_dict[stk] = cv\n",
    "                least_varied = sorted(stocks_cv_dict.items(), key=lambda x:x[1])[:n_cv]\n",
    "                for stk_tpl in least_varied:\n",
    "                    stk_name = stk_tpl[0]\n",
    "                    stocks_to_consider.append(stk_name)\n",
    "                    new_stocks_considered_row[sector].append(stk_name)\n",
    "            else:\n",
    "                for stk in top_cap_stocks:\n",
    "                    stocks_to_consider.append(stk_name)\n",
    "                    new_stocks_considered_row[sector].append(stk_name)\n",
    "        Stocks_considered_record[current_last_day] = new_stocks_considered_row\n",
    "\n",
    "        ### Clustering \n",
    "        possible_missclassified_stocks = []\n",
    "        if cluster == 'Yes':\n",
    "            if cluster_method == 'KMeans':\n",
    "                cluster_entry = K_mean_clustering(monthly_price_data[stocks_to_consider], num_clusters)\n",
    "            elif cluster_method == 'Spectral':\n",
    "                cluster_entry = spectral_clustering(monthly_price_data[stocks_to_consider], num_clusters)\n",
    "            for cluster_name in list(cluster_entry.keys()): # iterate over the n clusters\n",
    "                # pull the members and sort the sectors\n",
    "                cluster_members = cluster_entry[cluster_name]\n",
    "                new_clustering_row[f'Cluster_{int(cluster_name)+1}_Members'] = cluster_members\n",
    "                cluster_members_dict = {}\n",
    "                cluster_sectors = []\n",
    "                for stk in cluster_members:\n",
    "                    for sctr in market_dictionary:\n",
    "                        stocks_list = market_dictionary[sctr]\n",
    "                        if stk in stocks_list:\n",
    "                            if sctr not in cluster_sectors:\n",
    "                                cluster_sectors.append(sctr)\n",
    "                for sctr in cluster_sectors:\n",
    "                    cluster_members_dict[sctr] = []\n",
    "                for stk in cluster_members:\n",
    "                    for sctr in market_dictionary:\n",
    "                        stocks_list = market_dictionary[sctr]\n",
    "                        if stk in stocks_list:\n",
    "                            cluster_members_dict[sctr].append(stk)\n",
    "                # identify misclassified stocks\n",
    "                if len(cluster_sectors) > 1:\n",
    "                    sctr_lengths = np.array([len(value_list) for value_list in cluster_members_dict.values()])\n",
    "                    even_split = np.all(sctr_lengths == sctr_lengths[0])\n",
    "                    if even_split == False:\n",
    "                        cluster_members_cnt_dict = {}\n",
    "                        for sctr in cluster_members_dict:\n",
    "                            cluster_members_cnt_dict[sctr] = len(cluster_members_dict[sctr])\n",
    "                        highest_num_stks = max(cluster_members_cnt_dict.values())\n",
    "                        lowest_num_stks = min(cluster_members_cnt_dict.values())\n",
    "                        has_majority = list(cluster_members_cnt_dict.values()).count(highest_num_stks) == 1\n",
    "                        has_minority = list(cluster_members_cnt_dict.values()).count(lowest_num_stks) == 1\n",
    "                        if has_majority:\n",
    "                            if has_minority:\n",
    "                                minority_sctr = [sctr for sctr, count in cluster_members_cnt_dict.items() if count == lowest_num_stks][0]\n",
    "                                minority_stks = cluster_members_dict[minority_sctr]  \n",
    "                                if len(minority_stks) == 1:\n",
    "                                    possible_missclassified_stocks.append(minority_stks[0]) \n",
    "\n",
    "        ### Trading pt2: new trades\n",
    "        #print('...opening_trades...')\n",
    "        stocks_to_trade = []\n",
    "        if cluster == 'Yes':\n",
    "            for minority_stk in possible_missclassified_stocks:\n",
    "                if cluster_beta_validation == 'Yes':\n",
    "                    # find the minority stocks sector\n",
    "                    minority_sctr = ''\n",
    "                    for sctr in market_dictionary:\n",
    "                        sctrs_stocks = market_dictionary[sctr]\n",
    "                        if minority_stk in sctrs_stocks:\n",
    "                            minority_sctr = sctr\n",
    "                            break\n",
    "                    # view its peers and view their behavior, trade or not accordingly \n",
    "                    minority_sctr_stks = market_dictionary[minority_sctr]\n",
    "                    peer_stocks = []\n",
    "                    for possible_peer_stock in stocks_to_consider:\n",
    "                        if possible_peer_stock in minority_sctr_stks:\n",
    "                            peer_stocks.append(possible_peer_stock)\n",
    "                    peer_stocks.remove(minority_stk)\n",
    "                    up_cntr = 0\n",
    "                    down_cntr = 0\n",
    "                    for peer_stk in peer_stocks:\n",
    "                        stk_price_data = monthly_price_data[peer_stk]\n",
    "                        covariance = np.cov(range(len(stk_price_data)), stk_price_data.values)\n",
    "                        beta = covariance[0,1]\n",
    "                        if beta > 0:\n",
    "                            up_cntr +=1\n",
    "                        else:\n",
    "                            down_cntr +=1\n",
    "                    if (up_cntr == 0) or (down_cntr == 0):\n",
    "                        if up_cntr > 0: # peers are going up\n",
    "                            # check if the minority is going down\n",
    "                            minority_stk_price_data = monthly_price_data[minority_stk]\n",
    "                            covariance = np.cov(range(len(minority_stk_price_data)), minority_stk_price_data.values)\n",
    "                            beta = covariance[0,1]\n",
    "                            if beta < 0:\n",
    "                                stocks_to_trade.append((minority_stk, 'Long'))\n",
    "                        elif down_cntr > 0: # peers are going down\n",
    "                            # check if the minority is going up\n",
    "                            minority_stk_price_data = monthly_price_data[minority_stk]\n",
    "                            covariance = np.cov(range(len(minority_stk_price_data)), minority_stk_price_data.values)\n",
    "                            beta = covariance[0,1]\n",
    "                            if beta < 0:\n",
    "                                stocks_to_trade.append((minority_stk, 'Short'))\n",
    "                else:\n",
    "                    minority_stk_price_data = monthly_price_data[minority_stk]\n",
    "                    covariance = np.cov(range(len(minority_stk_price_data)), minority_stk_price_data.values)\n",
    "                    beta = covariance[0,1]\n",
    "                    if beta > 0: # short\n",
    "                        stocks_to_trade.append((minority_stk, 'Short'))\n",
    "                    else: # long\n",
    "                        stocks_to_trade.append((minority_stk, 'Long'))\n",
    "        else: # we didn't use clustering\n",
    "            for sctr in list(new_stocks_considered_row.keys()):\n",
    "                sctrs_stocks = new_stocks_considered_row[sctr]\n",
    "                sctrs_stocks_direction = {\n",
    "                    'Up': [],\n",
    "                    'Down': []\n",
    "                }\n",
    "                for stk in sctrs_stocks:\n",
    "                    stk_price_data = monthly_price_data[stk]\n",
    "                    covariance = np.cov(range(len(stk_price_data)), stk_price_data.values)\n",
    "                    beta = covariance[0,1]\n",
    "                    if beta > 0:\n",
    "                        sctrs_stocks_direction['Up'].append(stk)\n",
    "                    else:\n",
    "                        sctrs_stocks_direction['Down'].append(stk)\n",
    "                if len(sctrs_stocks_direction['Up']) == 1: # short\n",
    "                    stocks_to_trade.append((sctrs_stocks_direction['Up'][0], 'Short'))\n",
    "                if len(sctrs_stocks_direction['Down']) == 1: # long\n",
    "                    stocks_to_trade.append((sctrs_stocks_direction['Down'][0], 'Long'))\n",
    "        #print(f'Stocks to trade: {stocks_to_trade}')\n",
    "        if len(stocks_to_trade) > 0:\n",
    "            for trading_stock_tpl in stocks_to_trade:\n",
    "                stk_name = trading_stock_tpl[0]\n",
    "                trading_direction = trading_stock_tpl[1]\n",
    "                current_price = monthly_price_data.loc[current_last_day, stk_name]\n",
    "                if stk_name in list(trading_results_dict.keys()):\n",
    "                    trading_results_dict[stk_name]['Open_date'].append(current_last_day)\n",
    "                    trading_results_dict[stk_name]['Trade_type'].append(trading_direction)\n",
    "                    trading_results_dict[stk_name]['Open_price'].append(current_price)\n",
    "                else: \n",
    "                    trading_results_dict[stk_name] = {\n",
    "                        'Open_date':[current_last_day],\n",
    "                        'Close_date':[],\n",
    "                        'Trade_type':[trading_direction],\n",
    "                        'Open_price':[current_price],\n",
    "                        'Close_price':[],\n",
    "                        'Profit':[],\n",
    "                        }\n",
    "                #print(stk_name)\n",
    "                stocks_currently_in_trade.append(stk_name)   \n",
    "        #print(f'Stocks to trade: {stocks_to_trade}')\n",
    "        #print(f'Stocks currently in trade: {stocks_currently_in_trade}')                                \n",
    "\n",
    "        ### Cleanup\n",
    "        first_day = next_day # move days\n",
    "        clustering_output_data.append(new_clustering_row) # append the months data\n",
    "        \n",
    "    ### Output\n",
    "    clustering_results_df = pd.DataFrame(clustering_output_data)\n",
    "    clustering_results_df.set_index('timestamp', inplace=True)\n",
    "    return Stocks_considered_record, clustering_results_df, trading_results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cum_sum_plot_single(trading_results):\n",
    "    # Get all the possible timestamps\n",
    "    all_timestamps = sorted(set(ts for stock in trading_results for ts in trading_results[stock]['Close_date']))\n",
    "    temp_data = {\n",
    "        'Time': all_timestamps,\n",
    "        'Cumulative_Sum': []\n",
    "    }\n",
    "    cum_sum = 0\n",
    "    for timestamp in all_timestamps:\n",
    "        # Find profits for this timestamp\n",
    "        profits = []\n",
    "        for stock in trading_results:\n",
    "            for index_pos, ts in enumerate(trading_results[stock]['Close_date']):\n",
    "                if ts == timestamp:\n",
    "                    profits.append(trading_results[stock]['Profit'][index_pos])\n",
    "        # Ensure cumulative sum is increasing correctly\n",
    "        cum_sum += np.sum(profits)\n",
    "        temp_data['Cumulative_Sum'].append(cum_sum)\n",
    "    return pd.DataFrame(temp_data).set_index('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cum_sum_plot_multiple(*trading_results):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i, results in enumerate(trading_results):\n",
    "        all_timestamps = sorted(set(ts for stock in results for ts in results[stock]['Close_date']))    \n",
    "        temp_data = {\n",
    "            'Time': all_timestamps,\n",
    "            'Cumulative_Sum': []\n",
    "        }\n",
    "        cum_sum = 0\n",
    "        for timestamp in all_timestamps:\n",
    "            profits = []\n",
    "            for stock in results:\n",
    "                for index_pos, ts in enumerate(results[stock]['Close_date']):\n",
    "                    if ts == timestamp:\n",
    "                        profits.append(results[stock]['Profit'][index_pos])\n",
    "            \n",
    "            cum_sum += np.sum(profits)\n",
    "            temp_data['Cumulative_Sum'].append(cum_sum)\n",
    "\n",
    "        df = pd.DataFrame(temp_data).set_index('Time')\n",
    "        # Plot each dataset with a unique label\n",
    "        plt.plot(df.index, df['Cumulative_Sum'], label=f'Num Sectors: {i+2}')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Cumulative Sum')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_order = [\n",
    "    'Finance', \n",
    "    'Industrials',\n",
    "    'Real Estate', \n",
    "    'Health Care', \n",
    "    'Consumer Discretionary', \n",
    "    'Technology', \n",
    "    'Basic Materials', \n",
    "    'Consumer Staples', \n",
    "    'Energy', \n",
    "    'Utilities', \n",
    "    'Telecommunications']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stocks_considered, clustering_res, trading_res = trading(\n",
    "    prices_dataframe=train_df, caps_dataframe=caps_df, \n",
    "    market_dictionary=full_market_dict, sector_order=sector_order, \n",
    "    num_clusters=7, num_sectors=7, n_market_cap=10, n_cv=4, consider_cv='Yes',\n",
    "    cluster='Yes', cluster_beta_validation='Yes', cluster_method='KMeans',\n",
    "    num_months_to_run=115)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Running Trading Algorithm ---------------\n",
      "Running Order 1\n",
      "\n",
      "Running Order 2\n",
      "\n",
      "Running Order 3\n",
      "------------------ Validating Results ------------------\n",
      "Validating trading results dictionary:\n",
      "     results are consistent\n",
      "Validating Cumlative Sums:\n",
      "     results are consistent\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "# Define orders to run & constant variables\n",
    "sector_order_1 = ['Technology', 'Energy', 'Industrials']\n",
    "sector_order_2 = ['Industrials','Energy', 'Technology']\n",
    "sector_order_3 = ['Technology','Industrials','Energy']\n",
    "months_to_run = 5\n",
    "num_clusters = 3\n",
    "num_sectors = 3\n",
    "cluster_yn = 'No'\n",
    "cluster_method = 'KMeans'\n",
    "print('-------------- Running Trading Algorithm ---------------')\n",
    "print(f'Running Order 1')\n",
    "stock_selection_1, clustering_res_1, trading_res_1 = trading(\n",
    "        prices_dataframe=train_df, caps_dataframe=caps_df, \n",
    "        market_dictionary=full_market_dict, sector_order=sector_order_1, \n",
    "        num_clusters=num_clusters, num_sectors=num_sectors, n_market_cap=10, n_cv=4, consider_cv='Yes',\n",
    "        cluster=cluster_yn, cluster_beta_validation='Yes', cluster_method='KMeans',\n",
    "        num_months_to_run=months_to_run)\n",
    "print()\n",
    "print(f'Running Order 2')\n",
    "stock_selection_2, clustering_res_2, trading_res_2 = trading(\n",
    "        prices_dataframe=train_df, caps_dataframe=caps_df, \n",
    "        market_dictionary=full_market_dict, sector_order=sector_order_2, \n",
    "        num_clusters=num_clusters, num_sectors=num_sectors, n_market_cap=10, n_cv=4, consider_cv='Yes',\n",
    "        cluster=cluster_yn, cluster_beta_validation='Yes', cluster_method='KMeans',\n",
    "        num_months_to_run=months_to_run)\n",
    "print()\n",
    "print(f'Running Order 3')\n",
    "stock_selection_3, clustering_res_3, trading_res_3 = trading(\n",
    "        prices_dataframe=train_df, caps_dataframe=caps_df, \n",
    "        market_dictionary=full_market_dict, sector_order=sector_order_3, \n",
    "        num_clusters=num_clusters, num_sectors=num_sectors, n_market_cap=10, n_cv=4, consider_cv='Yes',\n",
    "        cluster=cluster_yn, cluster_beta_validation='Yes', cluster_method='KMeans',\n",
    "        num_months_to_run=months_to_run)\n",
    "print('------------------ Validating Results ------------------')\n",
    "print('Validating trading results dictionary:')\n",
    "if trading_res_1 == trading_res_2 == trading_res_3:\n",
    "    print('     results are consistent')\n",
    "else:\n",
    "    print('     results are not consistent')\n",
    "print('Validating Cumlative Sums:')\n",
    "cum_sum_1 = cum_sum_plot_single(trading_res_1)[-1:].values\n",
    "cum_sum_2 = cum_sum_plot_single(trading_res_2)[-1:].values\n",
    "cum_sum_3 = cum_sum_plot_single(trading_res_3)[-1:].values\n",
    "if cum_sum_1 == cum_sum_2 == cum_sum_3:\n",
    "    print('     results are consistent')\n",
    "else:\n",
    "    print('     results are not consistent')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
